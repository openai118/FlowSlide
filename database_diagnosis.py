#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
æ•°æ®åº“è¯Šæ–­å·¥å…· - è¯¦ç»†åˆ†ææ•°æ®åº“æ€§èƒ½å’Œé—®é¢˜
Database Diagnosis Tool - Detailed analysis of database performance and issues

ä½œè€…: AI Assistant
ç‰ˆæœ¬: 1.0.0
æ—¥æœŸ: 2025-08-13
"""

import os
import sys
import time
import json
import psycopg2
from datetime import datetime
from typing import Dict, List, Any, Optional
import logging

# é…ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
    handlers=[
        logging.StreamHandler(sys.stdout),
        logging.FileHandler('database_diagnosis.log', encoding='utf-8')
    ]
)
logger = logging.getLogger(__name__)

class DatabaseDiagnosis:
    """æ•°æ®åº“è¯Šæ–­ç±»"""
    
    def __init__(self):
        """åˆå§‹åŒ–è¯Šæ–­å·¥å…·"""
        self.db_config = {
            'host': os.getenv('DB_HOST', 'aws-0-ap-southeast-1.pooler.supabase.com'),
            'port': int(os.getenv('DB_PORT', 6543)),
            'database': os.getenv('DB_NAME', 'postgres'),
            'user': os.getenv('DB_USER', 'postgres.cweucknwqbtkyhsplbig'),
            'password': os.getenv('DB_PASSWORD', '')
        }
        self.connection: Optional[psycopg2.extensions.connection] = None
        self.diagnosis_results: Dict[str, Any] = {}
        
    def connect(self) -> bool:
        """è¿æ¥åˆ°æ•°æ®åº“"""
        try:
            self.connection = psycopg2.connect(**self.db_config)
            if self.connection:
                self.connection.autocommit = True
                logger.info("âœ… æ•°æ®åº“è¿æ¥æˆåŠŸ")
                return True
        except Exception as e:
            logger.error(f"âŒ æ•°æ®åº“è¿æ¥å¤±è´¥: {e}")
            self.connection = None
        return False
    
    def disconnect(self):
        """æ–­å¼€æ•°æ®åº“è¿æ¥"""
        if self.connection:
            self.connection.close()
            self.connection = None
            logger.info("ğŸ”Œ æ•°æ®åº“è¿æ¥å·²æ–­å¼€")
    
    def check_connection_metrics(self) -> Dict[str, Any]:
        """æ£€æŸ¥è¿æ¥æŒ‡æ ‡"""
        logger.info("ğŸ” æ£€æŸ¥è¿æ¥æŒ‡æ ‡...")
        metrics: Dict[str, Any] = {}
        
        try:
            if not self.connection:
                raise Exception("æ•°æ®åº“æœªè¿æ¥")
                
            cursor = self.connection.cursor()
            
            # å½“å‰è¿æ¥æ•°
            cursor.execute("SELECT count(*) FROM pg_stat_activity;")
            result = cursor.fetchone()
            metrics['total_connections'] = result[0] if result else 0
            
            # æ´»è·ƒè¿æ¥æ•°
            cursor.execute("SELECT count(*) FROM pg_stat_activity WHERE state = 'active';")
            result = cursor.fetchone()
            metrics['active_connections'] = result[0] if result else 0
            
            # ç©ºé—²è¿æ¥æ•°
            cursor.execute("SELECT count(*) FROM pg_stat_activity WHERE state = 'idle';")
            result = cursor.fetchone()
            metrics['idle_connections'] = result[0] if result else 0
            
            # æœ€å¤§è¿æ¥æ•°
            cursor.execute("SHOW max_connections;")
            result = cursor.fetchone()
            metrics['max_connections'] = int(result[0]) if result else 100
            
            # è¿æ¥ä½¿ç”¨ç‡
            if metrics['max_connections'] > 0:
                metrics['connection_usage_percent'] = (metrics['total_connections'] / metrics['max_connections']) * 100
            else:
                metrics['connection_usage_percent'] = 0
            
            cursor.close()
            
            logger.info(f"ğŸ“Š è¿æ¥æŒ‡æ ‡:")
            logger.info(f"   æ€»è¿æ¥æ•°: {metrics['total_connections']}")
            logger.info(f"   æ´»è·ƒè¿æ¥: {metrics['active_connections']}")
            logger.info(f"   ç©ºé—²è¿æ¥: {metrics['idle_connections']}")
            logger.info(f"   æœ€å¤§è¿æ¥: {metrics['max_connections']}")
            logger.info(f"   ä½¿ç”¨ç‡: {metrics['connection_usage_percent']:.1f}%")
            
        except Exception as e:
            logger.error(f"âŒ è¿æ¥æŒ‡æ ‡æ£€æŸ¥å¤±è´¥: {e}")
            metrics['error'] = str(e)
        
        return metrics
    
    def check_database_size(self) -> Dict[str, Any]:
        """æ£€æŸ¥æ•°æ®åº“å¤§å°"""
        logger.info("ğŸ’¾ æ£€æŸ¥æ•°æ®åº“å¤§å°...")
        size_info: Dict[str, Any] = {}
        
        try:
            if not self.connection:
                raise Exception("æ•°æ®åº“æœªè¿æ¥")
                
            cursor = self.connection.cursor()
            
            # æ•°æ®åº“æ€»å¤§å°
            cursor.execute("""
                SELECT pg_size_pretty(pg_database_size(current_database())) as db_size,
                       pg_database_size(current_database()) as db_size_bytes;
            """)
            result = cursor.fetchone()
            if result:
                size_info['database_size'] = result[0]
                size_info['database_size_bytes'] = result[1]
            
            # è¡¨å¤§å°æ’è¡Œ
            cursor.execute("""
                SELECT 
                    schemaname,
                    tablename,
                    pg_size_pretty(pg_total_relation_size(schemaname||'.'||tablename)) as size,
                    pg_total_relation_size(schemaname||'.'||tablename) as size_bytes
                FROM pg_tables 
                WHERE schemaname NOT IN ('information_schema', 'pg_catalog')
                ORDER BY pg_total_relation_size(schemaname||'.'||tablename) DESC
                LIMIT 10;
            """)
            
            tables = []
            for row in cursor.fetchall():
                tables.append({
                    'schema': row[0],
                    'table': row[1],
                    'size': row[2],
                    'size_bytes': row[3]
                })
            
            size_info['largest_tables'] = tables
            cursor.close()
            
            logger.info(f"ğŸ“Š æ•°æ®åº“å¤§å°: {size_info.get('database_size', 'Unknown')}")
            logger.info("ğŸ“Š æœ€å¤§çš„è¡¨:")
            for table in tables[:5]:
                logger.info(f"   {table['schema']}.{table['table']}: {table['size']}")
                
        except Exception as e:
            logger.error(f"âŒ æ•°æ®åº“å¤§å°æ£€æŸ¥å¤±è´¥: {e}")
            size_info['error'] = str(e)
        
        return size_info
    
    def check_query_performance(self) -> Dict[str, Any]:
        """æ£€æŸ¥æŸ¥è¯¢æ€§èƒ½"""
        logger.info("âš¡ æ£€æŸ¥æŸ¥è¯¢æ€§èƒ½...")
        performance: Dict[str, Any] = {}
        
        try:
            if not self.connection:
                raise Exception("æ•°æ®åº“æœªè¿æ¥")
                
            cursor = self.connection.cursor()
            
            # æ…¢æŸ¥è¯¢ç»Ÿè®¡
            try:
                cursor.execute("""
                    SELECT 
                        query,
                        calls,
                        total_time,
                        mean_time,
                        max_time,
                        min_time
                    FROM pg_stat_statements 
                    WHERE query NOT LIKE '%pg_stat_statements%'
                    ORDER BY total_time DESC 
                    LIMIT 10;
                """)
                
                slow_queries = []
                for row in cursor.fetchall():
                    slow_queries.append({
                        'query': row[0][:100] + '...' if len(row[0]) > 100 else row[0],
                        'calls': row[1],
                        'total_time': round(row[2], 2),
                        'mean_time': round(row[3], 2),
                        'max_time': round(row[4], 2),
                        'min_time': round(row[5], 2)
                    })
                
                performance['slow_queries'] = slow_queries
                
            except Exception as e:
                logger.warning(f"âš ï¸ pg_stat_statements ä¸å¯ç”¨: {e}")
                performance['slow_queries'] = []
            
            # é”ç­‰å¾…æ£€æŸ¥
            cursor.execute("""
                SELECT count(*) as blocked_queries
                FROM pg_locks 
                WHERE NOT granted;
            """)
            result = cursor.fetchone()
            performance['blocked_queries'] = result[0] if result else 0
            
            # æ´»è·ƒæŸ¥è¯¢
            cursor.execute("""
                SELECT count(*) as active_queries
                FROM pg_stat_activity 
                WHERE state = 'active' AND query NOT LIKE '%pg_stat_activity%';
            """)
            result = cursor.fetchone()
            performance['active_queries'] = result[0] if result else 0
            
            cursor.close()
            
            logger.info(f"ğŸ“Š æ€§èƒ½æŒ‡æ ‡:")
            logger.info(f"   æ´»è·ƒæŸ¥è¯¢: {performance['active_queries']}")
            logger.info(f"   é˜»å¡æŸ¥è¯¢: {performance['blocked_queries']}")
            logger.info(f"   æ…¢æŸ¥è¯¢è®°å½•: {len(performance['slow_queries'])}")
            
        except Exception as e:
            logger.error(f"âŒ æŸ¥è¯¢æ€§èƒ½æ£€æŸ¥å¤±è´¥: {e}")
            performance['error'] = str(e)
        
        return performance
    
    def run_basic_diagnosis(self) -> Dict[str, Any]:
        """è¿è¡ŒåŸºç¡€è¯Šæ–­ï¼ˆå¿«é€Ÿç‰ˆæœ¬ï¼‰"""
        logger.info("ğŸ”¬ å¼€å§‹åŸºç¡€æ•°æ®åº“è¯Šæ–­...")
        
        if not self.connect():
            return {'error': 'æ— æ³•è¿æ¥åˆ°æ•°æ®åº“'}
        
        start_time = time.time()
        
        # æ‰§è¡ŒåŸºç¡€è¯Šæ–­æ£€æŸ¥
        self.diagnosis_results = {
            'timestamp': datetime.now().isoformat(),
            'database_info': {
                'host': self.db_config['host'],
                'port': self.db_config['port'],
                'database': self.db_config['database']
            },
            'connection_metrics': self.check_connection_metrics(),
            'database_size': self.check_database_size(),
            'query_performance': self.check_query_performance()
        }
        
        end_time = time.time()
        self.diagnosis_results['diagnosis_duration'] = round(end_time - start_time, 2)
        
        self.disconnect()
        
        logger.info(f"âœ… åŸºç¡€è¯Šæ–­å®Œæˆï¼Œè€—æ—¶ {self.diagnosis_results['diagnosis_duration']} ç§’")
        
        return self.diagnosis_results
    
    def save_diagnosis_report(self, filename: Optional[str] = None) -> str:
        """ä¿å­˜è¯Šæ–­æŠ¥å‘Š"""
        if not filename:
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            filename = f"database_diagnosis_{timestamp}.json"
        
        try:
            with open(filename, 'w', encoding='utf-8') as f:
                json.dump(self.diagnosis_results, f, indent=2, ensure_ascii=False)
            
            logger.info(f"ğŸ“„ è¯Šæ–­æŠ¥å‘Šå·²ä¿å­˜: {filename}")
            return filename
        except Exception as e:
            logger.error(f"âŒ ä¿å­˜æŠ¥å‘Šå¤±è´¥: {e}")
            return ""
    
    def print_summary(self):
        """æ‰“å°è¯Šæ–­æ‘˜è¦"""
        if not self.diagnosis_results:
            logger.warning("âš ï¸ æ²¡æœ‰è¯Šæ–­ç»“æœå¯æ˜¾ç¤º")
            return
        
        print("\n" + "="*60)
        print("ğŸ“Š æ•°æ®åº“è¯Šæ–­æ‘˜è¦æŠ¥å‘Š")
        print("="*60)
        
        # è¿æ¥ä¿¡æ¯
        conn_metrics = self.diagnosis_results.get('connection_metrics', {})
        if 'total_connections' in conn_metrics:
            print(f"\nğŸ”Œ è¿æ¥çŠ¶æ€:")
            print(f"   æ€»è¿æ¥æ•°: {conn_metrics['total_connections']}")
            print(f"   æ´»è·ƒè¿æ¥: {conn_metrics['active_connections']}")
            print(f"   è¿æ¥ä½¿ç”¨ç‡: {conn_metrics['connection_usage_percent']:.1f}%")
        
        # æ•°æ®åº“å¤§å°
        db_size = self.diagnosis_results.get('database_size', {})
        if 'database_size' in db_size:
            print(f"\nğŸ’¾ æ•°æ®åº“å¤§å°: {db_size['database_size']}")
        
        # æ€§èƒ½æŒ‡æ ‡
        performance = self.diagnosis_results.get('query_performance', {})
        if 'active_queries' in performance:
            print(f"\nâš¡ æ€§èƒ½çŠ¶æ€:")
            print(f"   æ´»è·ƒæŸ¥è¯¢: {performance['active_queries']}")
            print(f"   é˜»å¡æŸ¥è¯¢: {performance['blocked_queries']}")
        
        print(f"\nâ±ï¸ è¯Šæ–­è€—æ—¶: {self.diagnosis_results['diagnosis_duration']} ç§’")
        print("="*60)

def main():
    """ä¸»å‡½æ•°"""
    print("ğŸ”¬ æ•°æ®åº“è¯Šæ–­å·¥å…·å¯åŠ¨")
    print("Database Diagnosis Tool Started")
    
    # æ£€æŸ¥ç¯å¢ƒå˜é‡
    required_env = ['DB_PASSWORD']
    missing_env = [env for env in required_env if not os.getenv(env)]
    
    if missing_env:
        logger.error(f"âŒ ç¼ºå°‘ç¯å¢ƒå˜é‡: {', '.join(missing_env)}")
        logger.info("ğŸ’¡ è¯·è®¾ç½®ä»¥ä¸‹ç¯å¢ƒå˜é‡:")
        logger.info("   export DB_PASSWORD='your_password'")
        logger.info("   export DB_HOST='your_host'  # å¯é€‰")
        logger.info("   export DB_PORT='your_port'  # å¯é€‰")
        logger.info("   export DB_NAME='your_db'    # å¯é€‰")
        logger.info("   export DB_USER='your_user'  # å¯é€‰")
        sys.exit(1)
    
    # è¿è¡Œè¯Šæ–­
    diagnosis = DatabaseDiagnosis()
    results = diagnosis.run_basic_diagnosis()
    
    if 'error' in results:
        logger.error(f"âŒ è¯Šæ–­å¤±è´¥: {results['error']}")
        sys.exit(1)
    
    # æ˜¾ç¤ºç»“æœ
    diagnosis.print_summary()
    
    # ä¿å­˜æŠ¥å‘Š
    report_file = diagnosis.save_diagnosis_report()
    if report_file:
        logger.info(f"ğŸ“„ è¯¦ç»†æŠ¥å‘Š: {report_file}")
    
    logger.info("ğŸ‰ æ•°æ®åº“è¯Šæ–­å®Œæˆ!")

if __name__ == "__main__":
    main()
