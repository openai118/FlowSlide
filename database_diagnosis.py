#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
æ•°æ®åº“è¯Šæ–­å·¥å…· - è¯¦ç»†åˆ†ææ•°æ®åº“æ€§èƒ½å’Œé—®é¢˜
Database Diagnosis Tool - Detailed analysis of database performance and issues

ä½œè€…: AI Assistant
ç‰ˆæœ¬: 2.0.0 - æ”¯æŒ DATABASE_URL é…ç½®
æ—¥æœŸ: 2025-08-13
"""

import os
import sys
import time
import json
import psycopg2
import urllib.parse
from datetime import datetime
from typing import Dict, List, Any, Optional
import logging

# é…ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
    handlers=[
        logging.StreamHandler(),
        logging.FileHandler('database_diagnosis.log', encoding='utf-8')
    ]
)
logger = logging.getLogger(__name__)


class DatabaseDiagnosis:
    """æ•°æ®åº“è¯Šæ–­å·¥å…·"""
    
    def __init__(self):
        """åˆå§‹åŒ–è¯Šæ–­å·¥å…·"""
        # ä¼˜å…ˆä½¿ç”¨ DATABASE_URLï¼Œå¦‚æœä¸å­˜åœ¨åˆ™ä½¿ç”¨åˆ†ç¦»çš„ç¯å¢ƒå˜é‡
        database_url = os.getenv('DATABASE_URL')
        
        if database_url:
            # è§£æ DATABASE_URL
            self.db_config = self._parse_database_url(database_url)
        else:
            # ä½¿ç”¨åˆ†ç¦»çš„ç¯å¢ƒå˜é‡ï¼ˆä¿æŒå‘åå…¼å®¹ï¼‰
            self.db_config = {
                'host': os.getenv('DB_HOST', 'localhost'),
                'port': int(os.getenv('DB_PORT', 5432)),
                'database': os.getenv('DB_NAME', 'postgres'),
                'user': os.getenv('DB_USER', 'postgres'),
                'password': os.getenv('DB_PASSWORD', ''),
                'sslmode': 'require'
            }
        
        self.connection = None
        self.diagnosis_results = {}
    
    def _parse_database_url(self, url):
        """è§£æ DATABASE_URL"""
        try:
            parsed = urllib.parse.urlparse(url)
            
            # è§£ææŸ¥è¯¢å‚æ•°
            query_params = urllib.parse.parse_qs(parsed.query)
            
            config = {
                'host': parsed.hostname,
                'port': parsed.port or 5432,
                'database': parsed.path.lstrip('/'),
                'user': parsed.username,
                'password': parsed.password,
                'sslmode': 'require'
            }
            
            # å¤„ç†ç‰¹æ®Šçš„ options å‚æ•°
            if 'options' in query_params:
                config['options'] = query_params['options'][0]
            
            return config
        except Exception as e:
            logger.error(f"âŒ è§£æ DATABASE_URL å¤±è´¥: {e}")
            sys.exit(1)
    
    def connect(self):
        """è¿æ¥åˆ°æ•°æ®åº“"""
        try:
            logger.info("ğŸ”— æ­£åœ¨è¿æ¥æ•°æ®åº“...")
            
            # éšè—å¯†ç æ˜¾ç¤º
            safe_config = self.db_config.copy()
            safe_config['password'] = '***'
            logger.info(f"è¿æ¥é…ç½®: {safe_config}")
            
            self.connection = psycopg2.connect(**self.db_config)
            if self.connection:
                self.connection.autocommit = True
                logger.info("âœ… æ•°æ®åº“è¿æ¥æˆåŠŸ")
                return True
        except Exception as e:
            logger.error(f"âŒ æ•°æ®åº“è¿æ¥å¤±è´¥: {e}")
            self.connection = None
        return False
    
    def disconnect(self):
        """æ–­å¼€æ•°æ®åº“è¿æ¥"""
        if self.connection:
            self.connection.close()
            self.connection = None
            logger.info("ğŸ”’ æ•°æ®åº“è¿æ¥å·²å…³é—­")
    
    def test_basic_connectivity(self):
        """æµ‹è¯•åŸºæœ¬è¿æ¥æ€§"""
        logger.info("ğŸ” æµ‹è¯•åŸºæœ¬è¿æ¥æ€§...")
        
        if not self.connection:
            return False
        
        try:
            cursor = self.connection.cursor()
            cursor.execute("SELECT version(), current_database(), current_user, now();")
            result = cursor.fetchone()
            
            if result:
                self.diagnosis_results['connectivity'] = {
                    'status': 'success',
                    'version': result[0],
                    'database': result[1],
                    'user': result[2],
                    'timestamp': str(result[3])
                }
                logger.info(f"âœ… è¿æ¥æµ‹è¯•æˆåŠŸ - æ•°æ®åº“: {result[1]}, ç”¨æˆ·: {result[2]}")
                return True
            
        except Exception as e:
            self.diagnosis_results['connectivity'] = {
                'status': 'failed',
                'error': str(e)
            }
            logger.error(f"âŒ è¿æ¥æµ‹è¯•å¤±è´¥: {e}")
        
        return False
    
    def analyze_database_performance(self):
        """åˆ†ææ•°æ®åº“æ€§èƒ½"""
        logger.info("âš¡ åˆ†ææ•°æ®åº“æ€§èƒ½...")
        
        if not self.connection:
            return False
        
        try:
            cursor = self.connection.cursor()
            
            # è·å–æ•°æ®åº“å¤§å°
            cursor.execute("""
                SELECT pg_database.datname,
                       pg_size_pretty(pg_database_size(pg_database.datname)) AS size
                FROM pg_database
                WHERE datname = current_database();
            """)
            db_size = cursor.fetchone()
            
            # è·å–æ´»è·ƒè¿æ¥æ•°
            cursor.execute("""
                SELECT count(*) as active_connections,
                       max_conn.setting::int as max_connections,
                       (count(*)::float / max_conn.setting::float * 100)::numeric(5,2) as usage_percent
                FROM pg_stat_activity psa
                CROSS JOIN (SELECT setting FROM pg_settings WHERE name = 'max_connections') max_conn
                WHERE state = 'active';
            """)
            connection_stats = cursor.fetchone()
            
            # è·å–ç¼“å­˜å‘½ä¸­ç‡
            cursor.execute("""
                SELECT sum(heap_blks_hit) as heap_hit,
                       sum(heap_blks_read) as heap_read,
                       round(sum(heap_blks_hit) / (sum(heap_blks_hit) + sum(heap_blks_read)) * 100, 2) as cache_hit_ratio
                FROM pg_statio_user_tables;
            """)
            cache_stats = cursor.fetchone()
            
            performance_data = {
                'database_size': db_size[1] if db_size else 'Unknown',
                'active_connections': connection_stats[0] if connection_stats else 0,
                'max_connections': connection_stats[1] if connection_stats else 0,
                'connection_usage_percent': float(connection_stats[2]) if connection_stats and connection_stats[2] else 0,
                'cache_hit_ratio': float(cache_stats[2]) if cache_stats and cache_stats[2] else 0
            }
            
            self.diagnosis_results['performance'] = performance_data
            
            logger.info(f"ğŸ“Š æ•°æ®åº“å¤§å°: {performance_data['database_size']}")
            logger.info(f"ğŸ“Š æ´»è·ƒè¿æ¥: {performance_data['active_connections']}/{performance_data['max_connections']} ({performance_data['connection_usage_percent']}%)")
            logger.info(f"ğŸ“Š ç¼“å­˜å‘½ä¸­ç‡: {performance_data['cache_hit_ratio']}%")
            
            return True
            
        except Exception as e:
            logger.error(f"âŒ æ€§èƒ½åˆ†æå¤±è´¥: {e}")
            self.diagnosis_results['performance'] = {'error': str(e)}
            return False
    
    def check_table_statistics(self):
        """æ£€æŸ¥è¡¨ç»Ÿè®¡ä¿¡æ¯"""
        logger.info("ğŸ“‹ æ£€æŸ¥è¡¨ç»Ÿè®¡ä¿¡æ¯...")
        
        if not self.connection:
            return False
        
        try:
            cursor = self.connection.cursor()
            
            # è·å–è¡¨çš„åŸºæœ¬ä¿¡æ¯
            cursor.execute("""
                SELECT schemaname, tablename, 
                       pg_size_pretty(pg_total_relation_size(schemaname||'.'||tablename)) as size,
                       n_tup_ins as inserts,
                       n_tup_upd as updates,
                       n_tup_del as deletes,
                       n_live_tup as live_tuples,
                       n_dead_tup as dead_tuples
                FROM pg_stat_user_tables
                ORDER BY pg_total_relation_size(schemaname||'.'||tablename) DESC
                LIMIT 10;
            """)
            
            tables = cursor.fetchall()
            
            table_stats = []
            for table in tables:
                table_stats.append({
                    'schema': table[0],
                    'table': table[1],
                    'size': table[2],
                    'inserts': table[3],
                    'updates': table[4],
                    'deletes': table[5],
                    'live_tuples': table[6],
                    'dead_tuples': table[7]
                })
            
            self.diagnosis_results['tables'] = table_stats
            
            logger.info(f"ğŸ“Š æ‰¾åˆ° {len(table_stats)} ä¸ªç”¨æˆ·è¡¨")
            for table in table_stats[:3]:  # æ˜¾ç¤ºå‰3ä¸ªæœ€å¤§çš„è¡¨
                logger.info(f"   ğŸ“‹ {table['schema']}.{table['table']}: {table['size']}, {table['live_tuples']} æ´»è·ƒè¡Œ")
            
            return True
            
        except Exception as e:
            logger.error(f"âŒ è¡¨ç»Ÿè®¡æ£€æŸ¥å¤±è´¥: {e}")
            self.diagnosis_results['tables'] = {'error': str(e)}
            return False
    
    def analyze_slow_queries(self):
        """åˆ†ææ…¢æŸ¥è¯¢"""
        logger.info("ğŸŒ åˆ†ææ…¢æŸ¥è¯¢...")
        
        if not self.connection:
            return False
        
        try:
            cursor = self.connection.cursor()
            
            # æ£€æŸ¥æ˜¯å¦å¯ç”¨äº†pg_stat_statementsæ‰©å±•
            cursor.execute("""
                SELECT EXISTS (
                    SELECT 1 FROM pg_extension WHERE extname = 'pg_stat_statements'
                );
            """)
            
            has_pg_stat_statements = cursor.fetchone()[0]
            
            if has_pg_stat_statements:
                # è·å–æœ€æ…¢çš„æŸ¥è¯¢
                cursor.execute("""
                    SELECT query, 
                           calls,
                           total_exec_time,
                           mean_exec_time,
                           max_exec_time,
                           rows
                    FROM pg_stat_statements
                    WHERE calls > 1
                    ORDER BY mean_exec_time DESC
                    LIMIT 5;
                """)
                
                slow_queries = cursor.fetchall()
                
                query_stats = []
                for query in slow_queries:
                    query_stats.append({
                        'query': query[0][:100] + '...' if len(query[0]) > 100 else query[0],
                        'calls': query[1],
                        'total_time': query[2],
                        'avg_time': query[3],
                        'max_time': query[4],
                        'rows': query[5]
                    })
                
                self.diagnosis_results['slow_queries'] = {
                    'enabled': True,
                    'queries': query_stats
                }
                
                logger.info(f"ğŸ“Š æ‰¾åˆ° {len(query_stats)} ä¸ªæ…¢æŸ¥è¯¢è®°å½•")
                
            else:
                self.diagnosis_results['slow_queries'] = {
                    'enabled': False,
                    'message': 'pg_stat_statements æ‰©å±•æœªå¯ç”¨'
                }
                logger.info("âš ï¸ pg_stat_statements æ‰©å±•æœªå¯ç”¨ï¼Œæ— æ³•åˆ†ææ…¢æŸ¥è¯¢")
            
            return True
            
        except Exception as e:
            logger.error(f"âŒ æ…¢æŸ¥è¯¢åˆ†æå¤±è´¥: {e}")
            self.diagnosis_results['slow_queries'] = {'error': str(e)}
            return False
    
    def check_index_usage(self):
        """æ£€æŸ¥ç´¢å¼•ä½¿ç”¨æƒ…å†µ"""
        logger.info("ğŸ—‚ï¸ æ£€æŸ¥ç´¢å¼•ä½¿ç”¨æƒ…å†µ...")
        
        if not self.connection:
            return False
        
        try:
            cursor = self.connection.cursor()
            
            # è·å–ç´¢å¼•ä½¿ç”¨ç»Ÿè®¡
            cursor.execute("""
                SELECT schemaname, tablename, indexname,
                       idx_tup_read, idx_tup_fetch,
                       pg_size_pretty(pg_relation_size(indexrelid)) as size
                FROM pg_stat_user_indexes
                ORDER BY idx_tup_read DESC
                LIMIT 10;
            """)
            
            indexes = cursor.fetchall()
            
            # æŸ¥æ‰¾æœªä½¿ç”¨çš„ç´¢å¼•
            cursor.execute("""
                SELECT schemaname, tablename, indexname,
                       pg_size_pretty(pg_relation_size(indexrelid)) as size
                FROM pg_stat_user_indexes
                WHERE idx_scan = 0 AND idx_tup_read = 0
                ORDER BY pg_relation_size(indexrelid) DESC;
            """)
            
            unused_indexes = cursor.fetchall()
            
            index_stats = {
                'used_indexes': [],
                'unused_indexes': []
            }
            
            for idx in indexes:
                index_stats['used_indexes'].append({
                    'schema': idx[0],
                    'table': idx[1],
                    'index': idx[2],
                    'reads': idx[3],
                    'fetches': idx[4],
                    'size': idx[5]
                })
            
            for idx in unused_indexes:
                index_stats['unused_indexes'].append({
                    'schema': idx[0],
                    'table': idx[1],
                    'index': idx[2],
                    'size': idx[3]
                })
            
            self.diagnosis_results['indexes'] = index_stats
            
            logger.info(f"ğŸ“Š æ´»è·ƒç´¢å¼•: {len(index_stats['used_indexes'])}")
            logger.info(f"ğŸ“Š æœªä½¿ç”¨ç´¢å¼•: {len(index_stats['unused_indexes'])}")
            
            return True
            
        except Exception as e:
            logger.error(f"âŒ ç´¢å¼•æ£€æŸ¥å¤±è´¥: {e}")
            self.diagnosis_results['indexes'] = {'error': str(e)}
            return False
    
    def generate_recommendations(self):
        """ç”Ÿæˆä¼˜åŒ–å»ºè®®"""
        logger.info("ğŸ’¡ ç”Ÿæˆä¼˜åŒ–å»ºè®®...")
        
        recommendations = []
        
        # åŸºäºè¿æ¥ä½¿ç”¨ç‡çš„å»ºè®®
        if 'performance' in self.diagnosis_results:
            perf = self.diagnosis_results['performance']
            
            if 'connection_usage_percent' in perf and perf['connection_usage_percent'] > 80:
                recommendations.append({
                    'type': 'warning',
                    'category': 'connections',
                    'message': f"è¿æ¥ä½¿ç”¨ç‡è¿‡é«˜ ({perf['connection_usage_percent']}%)ï¼Œå»ºè®®ä¼˜åŒ–è¿æ¥æ± é…ç½®"
                })
            
            if 'cache_hit_ratio' in perf and perf['cache_hit_ratio'] < 95:
                recommendations.append({
                    'type': 'warning',
                    'category': 'cache',
                    'message': f"ç¼“å­˜å‘½ä¸­ç‡è¾ƒä½ ({perf['cache_hit_ratio']}%)ï¼Œå»ºè®®å¢åŠ shared_buffersé…ç½®"
                })
        
        # åŸºäºæœªä½¿ç”¨ç´¢å¼•çš„å»ºè®®
        if 'indexes' in self.diagnosis_results:
            unused = self.diagnosis_results['indexes'].get('unused_indexes', [])
            if len(unused) > 0:
                recommendations.append({
                    'type': 'info',
                    'category': 'indexes',
                    'message': f"å‘ç° {len(unused)} ä¸ªæœªä½¿ç”¨çš„ç´¢å¼•ï¼Œè€ƒè™‘åˆ é™¤ä»¥èŠ‚çœç©ºé—´"
                })
        
        # åŸºäºè¡¨ç»Ÿè®¡çš„å»ºè®®
        if 'tables' in self.diagnosis_results:
            tables = self.diagnosis_results['tables']
            if isinstance(tables, list):
                for table in tables:
                    if table.get('dead_tuples', 0) > table.get('live_tuples', 0) * 0.1:
                        recommendations.append({
                            'type': 'warning',
                            'category': 'maintenance',
                            'message': f"è¡¨ {table['schema']}.{table['table']} æœ‰è¾ƒå¤šæ­»å…ƒç»„ï¼Œå»ºè®®è¿è¡Œ VACUUM"
                        })
        
        self.diagnosis_results['recommendations'] = recommendations
        
        logger.info(f"ğŸ’¡ ç”Ÿæˆäº† {len(recommendations)} æ¡ä¼˜åŒ–å»ºè®®")
        for rec in recommendations:
            icon = "âš ï¸" if rec['type'] == 'warning' else "â„¹ï¸"
            logger.info(f"   {icon} {rec['message']}")
    
    def save_diagnosis_report(self):
        """ä¿å­˜è¯Šæ–­æŠ¥å‘Š"""
        try:
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            filename = f"database_diagnosis_report_{timestamp}.json"
            
            report = {
                'metadata': {
                    'timestamp': datetime.now().isoformat(),
                    'tool_version': '2.0.0',
                    'database_config': {
                        'host': self.db_config.get('host', ''),
                        'database': self.db_config.get('database', ''),
                        'user': self.db_config.get('user', '')
                    }
                },
                'diagnosis': self.diagnosis_results
            }
            
            with open(filename, 'w', encoding='utf-8') as f:
                json.dump(report, f, ensure_ascii=False, indent=2, default=str)
            
            logger.info(f"ğŸ“„ è¯Šæ–­æŠ¥å‘Šå·²ä¿å­˜: {filename}")
            return filename
            
        except Exception as e:
            logger.error(f"âŒ ä¿å­˜æŠ¥å‘Šå¤±è´¥: {e}")
            return None
    
    def run_full_diagnosis(self):
        """è¿è¡Œå®Œæ•´è¯Šæ–­"""
        logger.info("ğŸš€ å¼€å§‹æ•°æ®åº“è¯Šæ–­...")
        logger.info("="*50)
        
        # è¿æ¥æ•°æ®åº“
        if not self.connect():
            logger.error("âŒ æ— æ³•è¿æ¥æ•°æ®åº“ï¼Œè¯Šæ–­ç»ˆæ­¢")
            return False
        
        try:
            # è¿è¡Œå„é¡¹æ£€æŸ¥
            checks = [
                self.test_basic_connectivity,
                self.analyze_database_performance,
                self.check_table_statistics,
                self.analyze_slow_queries,
                self.check_index_usage
            ]
            
            success_count = 0
            for check in checks:
                try:
                    if check():
                        success_count += 1
                    logger.info("-" * 30)
                except Exception as e:
                    logger.error(f"âŒ æ£€æŸ¥è¿‡ç¨‹å¼‚å¸¸: {e}")
            
            # ç”Ÿæˆå»ºè®®
            self.generate_recommendations()
            
            logger.info("="*50)
            logger.info("ğŸ“Š è¯Šæ–­æ€»ç»“")
            logger.info(f"âœ… å®Œæˆæ£€æŸ¥: {success_count}/{len(checks)}")
            
            if 'recommendations' in self.diagnosis_results:
                rec_count = len(self.diagnosis_results['recommendations'])
                logger.info(f"ğŸ’¡ ä¼˜åŒ–å»ºè®®: {rec_count} æ¡")
            
            # ä¿å­˜æŠ¥å‘Š
            report_file = self.save_diagnosis_report()
            if report_file:
                logger.info(f"ğŸ“„ è¯¦ç»†æŠ¥å‘Š: {report_file}")
            
            logger.info("ğŸ‰ æ•°æ®åº“è¯Šæ–­å®Œæˆ!")
            
            return success_count >= len(checks) * 0.7
            
        finally:
            self.disconnect()


def main():
    """ä¸»å‡½æ•°"""
    logger.info("ğŸ¥ æ•°æ®åº“è¯Šæ–­å·¥å…·")
    logger.info("ç‰ˆæœ¬: 2.0.0 | æ”¯æŒ DATABASE_URL å’Œç¯å¢ƒå˜é‡é…ç½®")
    logger.info("")
    
    # æ£€æŸ¥å¿…è¦çš„ç¯å¢ƒå˜é‡
    database_url = os.getenv('DATABASE_URL')
    has_separate_vars = all(os.getenv(var) for var in ['DB_HOST', 'DB_USER', 'DB_PASSWORD'])
    
    if not database_url and not has_separate_vars:
        logger.error("âŒ ç¼ºå°‘å¿…è¦çš„ç¯å¢ƒå˜é‡:")
        logger.error("   è¯·è®¾ç½® DATABASE_URL æˆ– (DB_HOST, DB_USER, DB_PASSWORD)")
        logger.error("")
        logger.error("ç¤ºä¾‹é…ç½®:")
        logger.error("DATABASE_URL=postgresql://user:pass@host:5432/dbname?sslmode=require")
        logger.error("æˆ–è€…:")
        logger.error("DB_HOST=your-host")
        logger.error("DB_USER=your-user") 
        logger.error("DB_PASSWORD=your-password")
        sys.exit(1)
    
    # è¿è¡Œè¯Šæ–­
    diagnosis = DatabaseDiagnosis()
    success = diagnosis.run_full_diagnosis()
    
    logger.info(f"\nğŸ¯ è¯Šæ–­å®Œæˆ! {'æˆåŠŸ' if success else 'å‘ç°é—®é¢˜'}")
    sys.exit(0 if success else 1)


if __name__ == "__main__":
    main()
