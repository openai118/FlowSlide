"""
Database configuration and session management with intelligent fallback strategy
"""

import logging
import os
import asyncio
from typing import Optional, Tuple
from pathlib import Path

from sqlalchemy import create_engine
from sqlalchemy.ext.asyncio import AsyncSession, async_sessionmaker, create_async_engine
from sqlalchemy.orm import sessionmaker

from ..core.simple_config import (
    DATABASE_URL,
    ASYNC_DATABASE_URL,
    LOCAL_DATABASE_URL,
    EXTERNAL_DATABASE_URL,
    DATABASE_MODE
)

logger = logging.getLogger(__name__)


class DatabaseManager:
    """Êô∫ËÉΩÊï∞ÊçÆÂ∫ìÁÆ°ÁêÜÂô®"""

    def __init__(self):
        self.local_url = LOCAL_DATABASE_URL
        self.local_async_url = LOCAL_DATABASE_URL.replace("sqlite:///", "sqlite+aiosqlite:///")
        self.external_url = EXTERNAL_DATABASE_URL
        self.external_async_url = EXTERNAL_DATABASE_URL.replace("postgresql://", "postgresql+asyncpg://") if EXTERNAL_DATABASE_URL.startswith("postgresql://") else ""

        self.primary_engine = None
        self.primary_async_engine = None
        self.external_engine = None
        self.external_async_engine = None
        self.engine = None  # ÂêëÂêéÂÖºÂÆπÁöÑÂà´Âêç

        self.database_type = "sqlite"
        self.sync_enabled = False

    def _ensure_data_directory(self):
        """Á°Æ‰øùÊï∞ÊçÆÁõÆÂΩïÂ≠òÂú®"""
        data_dir = Path("./data")
        data_dir.mkdir(exist_ok=True)
        logger.info(f"‚úÖ Data directory ready: {data_dir.absolute()}")

    def _create_local_engine(self):
        """ÂàõÂª∫Êú¨Âú∞SQLiteÂºïÊìé"""
        self._ensure_data_directory()
        self.primary_engine = create_engine(
            self.local_url,
            connect_args={"check_same_thread": False},
            echo=False,
        )
        self.primary_async_engine = create_async_engine(
            self.local_async_url,
            echo=False
        )
        self.engine = self.primary_engine  # ËÆæÁΩÆÂêëÂêéÂÖºÂÆπÁöÑÂà´Âêç
        self.database_type = "sqlite"
        logger.info("‚úÖ Local SQLite database ready")

    def _create_external_engine(self):
        """ÂàõÂª∫Â§ñÈÉ®Êï∞ÊçÆÂ∫ìÂºïÊìé"""
        if not self.external_url:
            raise ValueError("External database URL not configured")

        # Ëß£ÊûêÊï∞ÊçÆÂ∫ìURL‰ª•Ê£ÄÊµãÊòØÂê¶ÊòØSupabase
        from urllib.parse import urlparse
        parsed = urlparse(self.external_url)

        # Ê£ÄÊü•ÊòØÂê¶ÊòØSupabaseÔºàÈÄöËøáURLÁâπÂæÅËØÜÂà´Ôºâ
        is_supabase = ('supabase' in parsed.hostname if parsed.hostname else False) or ('pooler.supabase.com' in self.external_url)

        if is_supabase:
            # Supabase‰ΩøÁî®pgbouncerÔºåÈúÄË¶ÅÁâπÊÆäÈÖçÁΩÆ
            statement_cache_size = int(os.getenv("PG_STATEMENT_CACHE_SIZE", "0"))
            self.primary_engine = create_engine(
                self.external_url,
                pool_size=3,  # ËæÉÂ∞èÁöÑËøûÊé•Ê±†Â§ßÂ∞è
                max_overflow=2,  # ÂÖÅËÆ∏Â∞ëÈáèÊ∫¢Âá∫
                pool_pre_ping=False,  # Á¶ÅÁî®ËøûÊé•Ê±†ping‰ª•ÈÅøÂÖçprepared statements
                pool_recycle=300,  # Êõ¥È¢ëÁπÅÁöÑËøûÊé•ÂõûÊî∂
                pool_timeout=60,  # Â¢ûÂä†Ë∂ÖÊó∂Êó∂Èó¥
                echo=False
            )
            self.primary_async_engine = create_async_engine(
                self.external_async_url,
                pool_size=3,
                max_overflow=2,
                pool_pre_ping=False,
                pool_recycle=300,
                pool_timeout=60,
                echo=False,
                connect_args={"statement_cache_size": statement_cache_size}  # Á¶ÅÁî®prepared statements‰ª•ÂÖºÂÆπpgbouncer
            )
            logger.info("üéØ Detected Supabase - using pgbouncer-compatible configuration")
        else:
            # ÊôÆÈÄöPostgreSQLÈÖçÁΩÆ
            statement_cache_size = int(os.getenv("PG_STATEMENT_CACHE_SIZE", "0"))
            self.primary_engine = create_engine(
                self.external_url,
                pool_size=3,
                max_overflow=2,
                pool_pre_ping=False,
                pool_recycle=3600,
                pool_timeout=60,
                echo=False,
            )
            self.primary_async_engine = create_async_engine(
                self.external_async_url,
                pool_size=3,
                max_overflow=2,
                pool_pre_ping=False,
                pool_recycle=3600,
                pool_timeout=60,
                echo=False,
                connect_args={"statement_cache_size": statement_cache_size}  # ÂÖºÂÆπpgbouncer
            )

        self.engine = self.primary_engine  # ËÆæÁΩÆÂêëÂêéÂÖºÂÆπÁöÑÂà´Âêç
        self.database_type = "postgresql" if "postgresql" in self.external_url else "external"
        logger.info(f"‚úÖ External database ready: {self.database_type}")

    def _create_backup_engine(self):
        """ÂàõÂª∫Â§á‰ªΩÂºïÊìéÔºàÁî®‰∫éÊï∞ÊçÆÂêåÊ≠•Ôºâ"""
        if self.external_url:
            # Ëß£ÊûêÊï∞ÊçÆÂ∫ìURL‰ª•Ê£ÄÊµãÊòØÂê¶ÊòØSupabase
            from urllib.parse import urlparse
            parsed = urlparse(self.external_url)

            # Ê£ÄÊü•ÊòØÂê¶ÊòØSupabase
            is_supabase = 'supabase' in parsed.hostname if parsed.hostname else False

            # For Supabase/pgbouncer we only need to adjust async driver options
            # Do NOT pass statement_cache_size into the sync create_engine (psycopg2)
            async_connect_args = {}
            if is_supabase:
                # Supabase‰ΩøÁî®pgbouncerÔºåÈúÄË¶ÅÁ¶ÅÁî®prepared statements for asyncpg
                statement_cache_size = int(os.getenv("PG_STATEMENT_CACHE_SIZE", "0"))
                async_connect_args = {"statement_cache_size": statement_cache_size}

            # Create sync engine without passing DB-API specific connect_args that psycopg2 doesn't accept
            self.external_engine = create_engine(
                self.external_url,
                pool_size=5,
                max_overflow=10,
                pool_pre_ping=True,
                pool_recycle=3600,
                echo=False,
            )

            # Async engine may accept driver-specific connect_args (e.g., asyncpg)
            self.external_async_engine = create_async_engine(
                self.external_async_url,
                pool_size=5,
                max_overflow=10,
                pool_pre_ping=True,
                pool_recycle=3600,
                echo=False,
                connect_args=async_connect_args
            )
            logger.info("‚úÖ Backup database engine ready")

    def initialize(self):
        """ÂàùÂßãÂåñÊï∞ÊçÆÂ∫ìÁÆ°ÁêÜÂô®"""
        try:
            # Ê†πÊçÆÊ®°ÂºèÈÄâÊã©‰∏ªÊï∞ÊçÆÂ∫ì
            if DATABASE_MODE == "external" and self.external_url:
                try:
                    self._create_external_engine()
                    logger.info("üéØ Using external database as primary")
                except Exception as e:
                    logger.warning(f"‚ùå External database failed: {e}")
                    logger.info("üîÑ Falling back to local database")
                    self._create_local_engine()
            else:
                self._create_local_engine()
                logger.info("üè† Using local database as primary")

            # Â¶ÇÊûúÈÖçÁΩÆ‰∫ÜÂ§ñÈÉ®Êï∞ÊçÆÂ∫ìÔºåÂàõÂª∫Â§á‰ªΩÂºïÊìéÁî®‰∫éÂêåÊ≠•
            if self.external_url and DATABASE_MODE != "external":
                try:
                    self._create_backup_engine()
                    self.sync_enabled = True
                    logger.info("üîÑ Data synchronization enabled")
                except Exception as e:
                    logger.warning(f"‚ö†Ô∏è Backup engine creation failed: {e}")

        except Exception as e:
            logger.error(f"‚ùå Database manager initialization failed: {e}")
            raise

    async def sync_to_external(self):
        """ÂêåÊ≠•Êú¨Âú∞Êï∞ÊçÆÂà∞Â§ñÈÉ®Êï∞ÊçÆÂ∫ì"""
        if not self.sync_enabled or not self.external_engine:
            return

        try:
            logger.info("üîÑ Starting data synchronization to external database...")

            # ËøôÈáåÂèØ‰ª•ÂÆûÁé∞Êï∞ÊçÆÂêåÊ≠•ÈÄªËæë
            # ‰æãÂ¶ÇÔºöÂØºÂá∫Êú¨Âú∞Êï∞ÊçÆÔºåÂØºÂÖ•Âà∞Â§ñÈÉ®Êï∞ÊçÆÂ∫ì

            logger.info("‚úÖ Data synchronization completed")
        except Exception as e:
            logger.error(f"‚ùå Data synchronization failed: {e}")

    async def backup_to_r2(self):
        """Â§á‰ªΩÊï∞ÊçÆÂà∞R2"""
        try:
            # Ê£ÄÊü•R2ÈÖçÁΩÆ
            r2_access_key = os.getenv("R2_ACCESS_KEY_ID")
            r2_secret_key = os.getenv("R2_SECRET_ACCESS_KEY")
            r2_endpoint = os.getenv("R2_ENDPOINT")
            r2_bucket = os.getenv("R2_BUCKET_NAME")

            if not all([r2_access_key, r2_secret_key, r2_endpoint, r2_bucket]):
                logger.info("‚ÑπÔ∏è R2 not configured, skipping cloud backup")
                return

            logger.info("‚òÅÔ∏è Starting R2 backup...")

            # ËøôÈáåÂèØ‰ª•Ë∞ÉÁî®R2Â§á‰ªΩËÑöÊú¨ÊàñÂÆûÁé∞Â§á‰ªΩÈÄªËæë
            # Â§á‰ªΩÊú¨Âú∞Êï∞ÊçÆÂ∫ìÊñá‰ª∂ÂíåÈáçË¶ÅÊï∞ÊçÆ

            logger.info("‚úÖ R2 backup completed")
        except Exception as e:
            logger.error(f"‚ùå R2 backup failed: {e}")


# ÂàõÂª∫ÂÖ®Â±ÄÊï∞ÊçÆÂ∫ìÁÆ°ÁêÜÂô®ÂÆû‰æã
db_manager = DatabaseManager()

# ÂêëÂêéÂÖºÂÆπÁöÑÂèòÈáè
engine = None
async_engine = None
DATABASE_TYPE = "sqlite"

# ÂàùÂßãÂåñÊï∞ÊçÆÂ∫ìÁÆ°ÁêÜÂô®
def initialize_database():
    """ÂàùÂßãÂåñÊï∞ÊçÆÂ∫ìÁ≥ªÁªü"""
    global engine, async_engine, DATABASE_TYPE

    db_manager.initialize()

    engine = db_manager.primary_engine
    async_engine = db_manager.primary_async_engine
    DATABASE_TYPE = db_manager.database_type

    # Á°Æ‰øùÂêëÂêéÂÖºÂÆπÁöÑÂà´Âêç‰πüË¢´ËÆæÁΩÆ
    db_manager.engine = db_manager.primary_engine

    return db_manager


# ‰∏¥Êó∂ÂàõÂª∫Âü∫Êú¨ÁöÑsession makersÔºåÁ®çÂêé‰ºöÂú®initialize_database()‰∏≠Êõ¥Êñ∞
temp_engine = create_engine(
    "sqlite:///./data/flowslide.db",
    connect_args={"check_same_thread": False},
    echo=False,
)
temp_async_engine = create_async_engine("sqlite+aiosqlite:///./data/flowslide.db", echo=False)

SessionLocal = sessionmaker(autocommit=False, autoflush=False, bind=temp_engine)
AsyncSessionLocal = async_sessionmaker(temp_async_engine, class_=AsyncSession, expire_on_commit=False)


def get_db():
    """Dependency to get database session"""
    db = SessionLocal()
    try:
        yield db
    finally:
        db.close()


async def get_async_db():
    """Dependency to get async database session"""
    if AsyncSessionLocal:
        async with AsyncSessionLocal() as session:
            yield session
    else:
        raise RuntimeError("Async database session not available")


async def init_db():
    """Initialize database tables with error handling"""
    try:
        # Import here to avoid circular imports
        from .models import Base

        logger.info(f"üóÑÔ∏è Initializing database tables using {DATABASE_TYPE}...")

        if async_engine and engine:
            # Use sync engine for table creation to avoid pgbouncer issues
            with engine.begin() as conn:
                # Create all tables
                Base.metadata.create_all(bind=engine)

            logger.info("‚úÖ Database tables created successfully")

            # Initialize default admin user
            from ..auth.auth_service import init_default_admin
            import os

            def _external_has_users() -> bool:
                """Return True if external DB configured and contains at least one user."""
                try:
                    if not getattr(db_manager, "external_engine", None):
                        return False
                    with db_manager.external_engine.connect() as conn:
                        res = conn.execute(text("SELECT 1 FROM users LIMIT 1")).fetchone()
                        return bool(res)
                except Exception:
                    return False

            def _r2_has_backups_with_users() -> bool:
                """Lightweight check for R2: if R2 configured, assume backups may contain users. This is heuristic."""
                try:
                    r2_access_key = os.getenv("R2_ACCESS_KEY_ID")
                    r2_bucket = os.getenv("R2_BUCKET_NAME")
                    # If not configured, skip
                    if not r2_access_key or not r2_bucket:
                        return False
                    # Prefer not to import boto3 here; use heuristic that R2 is configured
                    return True
                except Exception:
                    return False

            db = SessionLocal()
            try:
                # Determine active deployment mode: prefer ACTIVE_DEPLOYMENT_MODE if set and not 'none'
                from ..core.deployment_mode_manager import mode_manager
                active_env = os.getenv("ACTIVE_DEPLOYMENT_MODE")
                if active_env and active_env.strip().lower() != 'none':
                    current_mode = None
                    try:
                        current_mode = mode_manager.current_mode
                    except Exception:
                        current_mode = None
                else:
                    # Query mode manager (this will perform auto-detection if needed)
                    try:
                        current_mode = mode_manager.current_mode or mode_manager.detect_current_mode()
                    except Exception:
                        current_mode = None

                # If current active mode is local-only (or explicitly set to local), create local admin
                mode_name = current_mode.value if current_mode else 'local_only'
                if mode_name.startswith('local') and ('external' not in mode_name and 'r2' not in mode_name):
                    init_default_admin(db)
                    logger.info("‚úÖ Default admin user initialized (active mode implies local-only)")
                else:
                    # For modes that include external or R2, prefer syncing users from external/R2 first
                    if _external_has_users():
                        # If local has no users yet, perform an initial full upsert from external -> local
                        try:
                            # check local user count
                            local_count = db.execute(text("SELECT COUNT(*) FROM users")).fetchone()[0]
                        except Exception:
                            local_count = 0

                        if local_count == 0:
                            logger.info("üì• External DB has users and local is empty - performing initial full upsert from external to local")
                            try:
                                # Perform upsert: read all external users and insert into local
                                if getattr(db_manager, 'external_engine', None):
                                    with db_manager.external_engine.connect() as ext_conn:
                                        rows = ext_conn.execute(text(
                                            "SELECT id, username, password_hash, email, is_admin, is_active, created_at, updated_at, last_login FROM users"
                                        )).fetchall()

                                        created = 0
                                        with SessionLocal() as local_session:
                                            for r in rows:
                                                try:
                                                    ext_id = r[0]
                                                    username = r[1]
                                                    password_hash = r[2]
                                                    email = r[3]
                                                    is_admin = bool(r[4]) if len(r) > 4 else False
                                                    is_active = bool(r[5]) if len(r) > 5 else True
                                                    created_at = r[6]
                                                    updated_at = r[7]
                                                    last_login = r[8]
                                                except Exception:
                                                    mapping = dict(r)
                                                    ext_id = mapping.get('id')
                                                    username = mapping.get('username')
                                                    password_hash = mapping.get('password_hash')
                                                    email = mapping.get('email')
                                                    is_admin = bool(mapping.get('is_admin'))
                                                    is_active = bool(mapping.get('is_active', True))
                                                    created_at = mapping.get('created_at')
                                                    updated_at = mapping.get('updated_at')
                                                    last_login = mapping.get('last_login')

                                                if not username or not password_hash:
                                                    continue

                                                # insert if not exists
                                                exists = local_session.execute(text("SELECT id FROM users WHERE username=:u LIMIT 1"), {"u": username}).fetchone()
                                                if exists:
                                                    continue
                                                try:
                                                    local_session.execute(text(
                                                        "INSERT INTO users (id, username, password_hash, email, is_admin, is_active, created_at, updated_at, last_login) VALUES (:id,:username,:hash,:email,:is_admin,:is_active,:created_at,:updated_at,:last_login)"
                                                    ), {"id": ext_id, "username": username, "hash": password_hash, "email": email, "is_admin": is_admin, "is_active": is_active, "created_at": created_at, "updated_at": updated_at, "last_login": last_login})
                                                    created += 1
                                                except Exception as e:
                                                    try:
                                                        local_session.rollback()
                                                    except Exception:
                                                        pass
                                                    logger.warning(f"‚ö†Ô∏è Failed to insert external user {username} during init upsert: {e}")

                                            try:
                                                local_session.commit()
                                            except Exception:
                                                try:
                                                    local_session.rollback()
                                                except Exception:
                                                    pass

                                        logger.info(f"‚úÖ Initial upsert completed: created={created} from external")
                                else:
                                    logger.warning("External engine not available - cannot perform initial upsert")
                            except Exception as e:
                                logger.warning(f"Initial external->local upsert failed: {e}")
                        else:
                            logger.info("‚ÑπÔ∏è External DB has users - local already contains users, skipping initial upsert")
                    elif _r2_has_backups_with_users():
                        logger.info("‚ÑπÔ∏è R2 appears configured - will rely on R2/external backups for initial users and skip local admin creation if possible")
                    else:
                        init_default_admin(db)
                        logger.info("‚úÖ Default admin user initialized (no external/R2 users found)")
            except Exception as e:
                logger.warning(f"‚ö†Ô∏è Admin user initialization warning: {e}")
            finally:
                db.close()
        else:
            raise RuntimeError("Database engine not initialized")

    except Exception as e:
        logger.error(f"‚ùå Database initialization failed: {e}")
        # Try to handle the error gracefully
        if "postgresql" in str(e).lower() or "asyncpg" in str(e).lower():
            logger.error("üí° Hint: This appears to be a PostgreSQL connection issue.")
            logger.error("   Consider checking your DATABASE_URL or using SQLite as fallback.")
        raise


async def close_db():
    """Close database connections"""
    if async_engine:
        await async_engine.dispose()


def update_session_makers():
    """Êõ¥Êñ∞session makers‰ª•‰ΩøÁî®Ê≠£Á°ÆÁöÑÂºïÊìé"""
    global SessionLocal, AsyncSessionLocal

    if engine:
        SessionLocal = sessionmaker(autocommit=False, autoflush=False, bind=engine)

    if async_engine:
        AsyncSessionLocal = async_sessionmaker(async_engine, class_=AsyncSession, expire_on_commit=False)
