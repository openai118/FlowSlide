"""
Database configuration and session management with intelligent fallback strategy
"""

import logging
import os
import asyncio
from typing import Optional, Tuple
from pathlib import Path

from sqlalchemy import create_engine, text
from sqlalchemy.ext.asyncio import AsyncSession, async_sessionmaker, create_async_engine
from sqlalchemy.orm import sessionmaker

from ..core.simple_config import (
    DATABASE_URL,
    ASYNC_DATABASE_URL,
    LOCAL_DATABASE_URL,
    EXTERNAL_DATABASE_URL,
    DATABASE_MODE
)

logger = logging.getLogger(__name__)


class DatabaseManager:
    """æ™ºèƒ½æ•°æ®åº“ç®¡ç†å™¨"""

    def __init__(self):
        self.local_url = LOCAL_DATABASE_URL
        self.local_async_url = LOCAL_DATABASE_URL.replace("sqlite:///", "sqlite+aiosqlite:///")
        # ä»…æ¥å—çœŸæ­£çš„å¤–éƒ¨æ•°æ®åº“URLï¼ˆpostgresql/mysqlï¼‰ï¼Œå¦åˆ™è§†ä¸ºæœªé…ç½®
        _raw_ext = (EXTERNAL_DATABASE_URL or "").strip()
        if _raw_ext:
            # Accept schemes like 'postgresql', 'postgresql+asyncpg', 'mysql', 'mysql+aiomysql', etc.
            try:
                from urllib.parse import urlparse
                parsed = urlparse(_raw_ext)
                scheme = (parsed.scheme or "").lower()

                if scheme.startswith("postgresql") or scheme.startswith("mysql"):
                    # keep the original URL as external_url (may already include +driver)
                    self.external_url = _raw_ext
                    # compute async form using helper which also strips unsupported query params
                    try:
                        from ..core.simple_config import get_async_database_url
                        self.external_async_url = get_async_database_url(_raw_ext)
                    except Exception:
                        # fallback: attempt conservative replacements
                        if scheme.startswith("postgresql"):
                            if "asyncpg" in scheme:
                                self.external_async_url = _raw_ext
                            else:
                                self.external_async_url = _raw_ext.replace(scheme + "://", "postgresql+asyncpg://", 1)
                        elif scheme.startswith("mysql"):
                            if "aiomysql" in scheme:
                                self.external_async_url = _raw_ext
                            else:
                                self.external_async_url = _raw_ext.replace(scheme + "://", "mysql+aiomysql://", 1)
                        else:
                            self.external_async_url = ""
                else:
                    logger.info("â„¹ï¸ DATABASE_URL is not a supported external DB (postgresql/mysql). Ignoring for external engines.")
                    self.external_url = ""
                    self.external_async_url = ""
            except Exception:
                # If parsing fails, fall back to empty external config
                logger.info("â„¹ï¸ Failed to parse EXTERNAL_DATABASE_URL - ignoring as external DB")
                self.external_url = ""
                self.external_async_url = ""
        else:
            self.external_url = ""
            self.external_async_url = ""

        self.primary_engine = None
        self.primary_async_engine = None
        self.external_engine = None
        self.external_async_engine = None
        self.engine = None  # å‘åå…¼å®¹çš„åˆ«å

        self.database_type = "sqlite"
        self.sync_enabled = False

    def _ensure_data_directory(self):
        """ç¡®ä¿æ•°æ®ç›®å½•å­˜åœ¨"""
        data_dir = Path("./data")
        data_dir.mkdir(exist_ok=True)
        logger.info(f"âœ… Data directory ready: {data_dir.absolute()}")

    def _create_local_engine(self):
        """åˆ›å»ºæœ¬åœ°SQLiteå¼•æ“"""
        self._ensure_data_directory()
        self.primary_engine = create_engine(
            self.local_url,
            connect_args={"check_same_thread": False},
            echo=False,
        )
        # Use safe async engine creator to ensure asyncpg statement cache is disabled when needed
        self.primary_async_engine = create_async_engine_safe(
            self.local_async_url,
            echo=False
        )
        self.engine = self.primary_engine  # è®¾ç½®å‘åå…¼å®¹çš„åˆ«å
        self.database_type = "sqlite"
        logger.info("âœ… Local SQLite database ready")

    def _create_external_engine(self):
        """åˆ›å»ºå¤–éƒ¨æ•°æ®åº“å¼•æ“"""
        if not self.external_url:
            raise ValueError("External database URL not configured")

        try:
            # è§£ææ•°æ®åº“URLä»¥æ£€æµ‹æ˜¯å¦æ˜¯ Supabase æˆ– pgbouncer/pooler
            from urllib.parse import urlparse
            parsed = urlparse(self.external_url)

            hostname = parsed.hostname or ""
            url_lc = (self.external_url or "").lower()

            # æ£€æŸ¥æ˜¯å¦æ˜¯ Supabase æˆ–å¸¸è§çš„ pgbouncer/pooler ç‰¹å¾
            is_supabase = ("supabase" in hostname) or ("pooler.supabase.com" in url_lc)
            is_pooler = any(key in hostname or key in url_lc for key in ("pooler", "pgbouncer", "pgbouncer."))

            # å¼ºåˆ¶æ‰€æœ‰ asyncpg åœºæ™¯ç¦ç”¨ prepared statement ç¼“å­˜ï¼Œé¿å… pgbouncer é—®é¢˜
            # Increase pool sizes to better handle concurrent requests when
            # using an external database. Keep relatively conservative defaults
            # but higher than the previous tiny values.
            self.primary_engine = create_engine(
                self.external_url,
                pool_size=10,
                max_overflow=20,
                pool_pre_ping=False,
                pool_recycle=(300 if is_supabase or is_pooler else 3600),
                pool_timeout=60,
                echo=False,
            )

            async_connect_args = {"statement_cache_size": 0}
            self.primary_async_engine = create_async_engine_safe(
                self.external_async_url,
                pool_size=3,
                max_overflow=2,
                pool_pre_ping=False,
                pool_recycle=(300 if is_supabase or is_pooler else 3600),
                pool_timeout=60,
                echo=False,
                connect_args=async_connect_args,
            )
            logger.info("ğŸ”’ asyncpg statement_cache_size=0 å¼ºåˆ¶å…³é—­ï¼Œé¿å… pgbouncer/prepared statement é—®é¢˜")

            # æµ‹è¯•æ•°æ®åº“è¿æ¥
            logger.info("ğŸ” Testing database connection...")
            with self.primary_engine.connect() as conn:
                conn.execute(text("SELECT 1"))
            logger.info("âœ… Database connection test successful")

            self.engine = self.primary_engine  # è®¾ç½®å‘åå…¼å®¹çš„åˆ«å
            self.external_engine = self.primary_engine  # è®¾ç½®å¤–éƒ¨å¼•æ“å¼•ç”¨
            self.database_type = "postgresql" if "postgresql" in self.external_url else "external"
            logger.info(f"âœ… External database ready: {self.database_type}")

        except Exception as e:
            logger.error(f"âŒ Failed to create external database engine: {e}")
            raise

    def _create_backup_engine(self):
        """åˆ›å»ºå¤‡ä»½å¼•æ“ï¼ˆç”¨äºæ•°æ®åŒæ­¥ï¼‰"""
        if self.external_url:
            # è§£ææ•°æ®åº“URLä»¥æ£€æµ‹æ˜¯å¦æ˜¯Supabase
            from urllib.parse import urlparse
            parsed = urlparse(self.external_url)

            # æ£€æŸ¥æ˜¯å¦æ˜¯Supabase
            is_supabase = 'supabase' in parsed.hostname if parsed.hostname else False

            # For Supabase/pgbouncer we only need to adjust async driver options
            # Do NOT pass statement_cache_size into the sync create_engine (psycopg2)
            # å¼ºåˆ¶æ‰€æœ‰ asyncpg åœºæ™¯ç¦ç”¨ prepared statement ç¼“å­˜ï¼Œé¿å… pgbouncer é—®é¢˜
            async_connect_args = {"statement_cache_size": 0}
            # Create sync engine without passing DB-API specific connect_args that psycopg2 doesn't accept
            # Backup engine used for synchronization; increase pool sizes
            # so simultaneous sync/requests don't starve connections.
            self.external_engine = create_engine(
                self.external_url,
                pool_size=10,
                max_overflow=20,
                pool_pre_ping=True,
                pool_recycle=3600,
                echo=False,
            )

            # Async engine may accept driver-specific connect_args (e.g., asyncpg)
            self.external_async_engine = create_async_engine_safe(
                self.external_async_url,
                pool_size=5,
                max_overflow=10,
                pool_pre_ping=True,
                pool_recycle=3600,
                echo=False,
                connect_args=async_connect_args
            )
            logger.info("âœ… Backup database engine ready")

    def initialize(self):
        """åˆå§‹åŒ–æ•°æ®åº“ç®¡ç†å™¨"""
        try:
            # è·å–å½“å‰éƒ¨ç½²æ¨¡å¼
            from ..core.deployment_mode_manager import mode_manager
            current_mode = mode_manager.current_mode or mode_manager.detect_current_mode()
            mode_name = current_mode.value if current_mode else 'local_only'

            # æ ¹æ®æ¨¡å¼é€‰æ‹©ä¸»æ•°æ®åº“
            # è¯­ä¹‰è¯´æ˜:
            # - è‹¥æ˜¾å¼é€šè¿‡ç¯å¢ƒå˜é‡æˆ– DATABASE_MODE æŒ‡å®š externalï¼Œåˆ™ä½¿ç”¨å¤–éƒ¨æ•°æ®åº“ä¸ºä¸»
            # - å¯¹äº local_external æœ¬åœ°ä¼˜å…ˆåœºæ™¯ï¼Œé»˜è®¤ä½¿ç”¨æœ¬åœ°ä¸ºä¸»ï¼ˆlocal read, external writeï¼‰ä»¥ä¿è¯ UI å»¶è¿Ÿä½
            # - å¦‚éœ€å¼ºåˆ¶åœ¨ local_external ä¸‹ä½¿ç”¨å¤–éƒ¨ä¸ºä¸»ï¼Œå¯è®¾ç½®ç¯å¢ƒå˜é‡ PREFER_EXTERNAL_AS_PRIMARY=1
            prefer_external_env = os.getenv("PREFER_EXTERNAL_AS_PRIMARY", "").strip().lower() in ("1", "true", "yes")
            prefer_external = (DATABASE_MODE == "external") or prefer_external_env

            if prefer_external and self.external_url:
                try:
                    # å¤–éƒ¨è¢«æ˜ç¡®é€‰ä¸ºä¸»åº“
                    self._create_external_engine()
                    logger.info("ğŸ¯ Using external database as primary")
                except Exception as e:
                    logger.warning(f"âŒ External database failed: {e}")
                    logger.info("ğŸ”„ Falling back to local database")
                    self._create_local_engine()
            else:
                # é»˜è®¤ä½¿ç”¨æœ¬åœ°ä½œä¸ºä¸»åº“ï¼Œå¤–éƒ¨ä½œä¸ºå¤‡ä»½ï¼ˆç”¨äºå¼‚æ­¥åŒæ­¥ï¼‰
                self._create_local_engine()
                logger.info("ğŸ  Using local database as primary (local read / external write)")

            # å¦‚æœé…ç½®äº†å¤–éƒ¨æ•°æ®åº“ä¸”ä¸æ˜¯externalæ¨¡å¼ï¼Œåˆ›å»ºå¤‡ä»½å¼•æ“ç”¨äºåŒæ­¥
            if self.external_url and DATABASE_MODE != "external" and mode_name not in ['local_external', 'local_external_r2']:
                try:
                    self._create_backup_engine()
                    self.sync_enabled = True
                    logger.info("ğŸ”„ Data synchronization enabled")
                except Exception as e:
                    logger.warning(f"âš ï¸ Backup engine creation failed: {e}")

            # å¦‚æœå½“å‰éƒ¨ç½²æ¨¡å¼åŒ…å« externalï¼ˆæˆ–è€…æ˜¾å¼è®¾ç½®ä¸º externalï¼‰ï¼Œç¡®ä¿å¤–éƒ¨æ•°æ®åº“è¢«åˆå§‹åŒ–
            try:
                wants_external = (DATABASE_MODE == "external") or (mode_name in ['local_external', 'local_external_r2'])
                if wants_external and self.external_engine:
                    logger.info("ğŸ”§ Ensuring external database tables and default admin (if needed)...")
                    try:
                        # å¯¼å…¥æ¨¡å‹å¹¶åœ¨å¤–éƒ¨ DB ä¸Šåˆ›å»ºè¡¨ï¼ˆä½¿ç”¨åŒæ­¥å¼•æ“ä»¥é¿å… asyncpg/pooler é—®é¢˜ï¼‰
                        from .models import Base
                        with self.external_engine.begin() as conn:
                            Base.metadata.create_all(bind=self.external_engine)

                        # åˆå§‹åŒ–é»˜è®¤ç®¡ç†å‘˜åˆ°å¤–éƒ¨æ•°æ®åº“ï¼ˆå¦‚æœæ²¡æœ‰ç”¨æˆ·ï¼‰
                        from ..auth.auth_service import init_default_admin
                        from sqlalchemy.orm import sessionmaker
                        ExternalSession = sessionmaker(autocommit=False, autoflush=False, bind=self.external_engine)
                        ext_db = ExternalSession()
                        try:
                            init_default_admin(ext_db)
                            logger.info("âœ… External database default admin initialized (if it was missing)")
                        except Exception as _e:
                            logger.warning(f"âš ï¸ åˆå§‹åŒ–å¤–éƒ¨æ•°æ®åº“é»˜è®¤ç®¡ç†å‘˜æ—¶å‡ºé”™ï¼ˆå¿½ç•¥ï¼‰: {_e}")
                        finally:
                            try:
                                ext_db.close()
                            except Exception:
                                pass

                    except Exception as _ext_init_e:
                        logger.warning(f"âš ï¸ ç¡®ä¿å¤–éƒ¨æ•°æ®åº“åˆå§‹åŒ–å¤±è´¥ï¼ˆç»§ç»­ï¼‰: {_ext_init_e}")
            except Exception:
                # é˜²å¾¡æ€§æ•è·ï¼Œä¸å½±å“ä¸»æµç¨‹
                pass

        except Exception as e:
            logger.error(f"âŒ Database manager initialization failed: {e}")
            raise

    async def sync_to_external(self):
        """åŒæ­¥æœ¬åœ°æ•°æ®åˆ°å¤–éƒ¨æ•°æ®åº“"""
        if not self.sync_enabled or not self.external_engine:
            return

        try:
            logger.info("ğŸ”„ Starting data synchronization to external database...")

            # è¿™é‡Œå¯ä»¥å®ç°æ•°æ®åŒæ­¥é€»è¾‘
            # ä¾‹å¦‚ï¼šå¯¼å‡ºæœ¬åœ°æ•°æ®ï¼Œå¯¼å…¥åˆ°å¤–éƒ¨æ•°æ®åº“

            logger.info("âœ… Data synchronization completed")
        except Exception as e:
            logger.error(f"âŒ Data synchronization failed: {e}")

    async def backup_to_r2(self):
        """å¤‡ä»½æ•°æ®åˆ°R2"""
        try:
            # æ£€æŸ¥R2é…ç½®
            r2_access_key = os.getenv("R2_ACCESS_KEY_ID")
            r2_secret_key = os.getenv("R2_SECRET_ACCESS_KEY")
            r2_endpoint = os.getenv("R2_ENDPOINT")
            r2_bucket = os.getenv("R2_BUCKET_NAME")

            if not all([r2_access_key, r2_secret_key, r2_endpoint, r2_bucket]):
                logger.info("â„¹ï¸ R2 not configured, skipping cloud backup")
                return

            logger.info("â˜ï¸ Starting R2 backup...")

            # è¿™é‡Œå¯ä»¥è°ƒç”¨R2å¤‡ä»½è„šæœ¬æˆ–å®ç°å¤‡ä»½é€»è¾‘
            # å¤‡ä»½æœ¬åœ°æ•°æ®åº“æ–‡ä»¶å’Œé‡è¦æ•°æ®

            logger.info("âœ… R2 backup completed")
        except Exception as e:
            logger.error(f"âŒ R2 backup failed: {e}")


# åˆ›å»ºå…¨å±€æ•°æ®åº“ç®¡ç†å™¨å®ä¾‹
db_manager = DatabaseManager()

# å‘åå…¼å®¹çš„å˜é‡
engine = None
async_engine = None
DATABASE_TYPE = "sqlite"

# åˆå§‹åŒ–æ•°æ®åº“ç®¡ç†å™¨
def initialize_database():
    """åˆå§‹åŒ–æ•°æ®åº“ç³»ç»Ÿ"""
    global engine, async_engine, DATABASE_TYPE

    db_manager.initialize()

    engine = db_manager.primary_engine
    async_engine = db_manager.primary_async_engine
    DATABASE_TYPE = db_manager.database_type

    # ç¡®ä¿å‘åå…¼å®¹çš„åˆ«åä¹Ÿè¢«è®¾ç½®
    db_manager.engine = db_manager.primary_engine

    return db_manager


# ä¸´æ—¶åˆ›å»ºåŸºæœ¬çš„session makersï¼Œç¨åä¼šåœ¨initialize_database()ä¸­æ›´æ–°
temp_engine = create_engine(
    "sqlite:///./data/flowslide.db",
    connect_args={"check_same_thread": False},
    echo=False,
)
def create_async_engine_safe(url: str, **kwargs):
    """
    Wrapper around SQLAlchemy's create_async_engine to ensure that when using asyncpg
    we pass connect_args={'statement_cache_size': 0} to avoid pgbouncer prepared statement issues.
    It merges user-provided connect_args with the enforced setting.
    """
    # Normalize common sync URLs (postgresql://, mysql://) to their async counterparts
    try:
        lower = (url or "").lower()
    except Exception:
        lower = ""

    # If caller passed a sync URL like postgresql://... or mysql://... convert it
    # to async form to avoid errors like "The asyncio extension requires an async driver".
    try:
        if lower.startswith("postgresql://") and "asyncpg" not in lower:
            from ..core.simple_config import get_async_database_url
            async_url = get_async_database_url(url)
            logger.info(f"create_async_engine_safe: converted sync postgresql URL to async form: {async_url}")
            url = async_url
            lower = url.lower()
        elif lower.startswith("mysql://") and "aiomysql" not in lower:
            from ..core.simple_config import get_async_database_url
            async_url = get_async_database_url(url)
            logger.info(f"create_async_engine_safe: converted sync mysql URL to async form: {async_url}")
            url = async_url
            lower = url.lower()
    except Exception as _conv_e:
        # If conversion fails, fall back and let create_async_engine raise a meaningful error
        logger.debug(f"create_async_engine_safe: async URL conversion attempt failed: {_conv_e}")

    # Only enforce for asyncpg URLs
    if "asyncpg" in lower:
        enforced = {"statement_cache_size": 0}
        user_ca = kwargs.get("connect_args") or {}
        # Merge without overwriting user-specified keys except statement_cache_size
        merged = {**user_ca, **enforced}
        kwargs["connect_args"] = merged
        logger.info(f"create_async_engine_safe: forcing asyncpg connect_args for {url}: {kwargs.get('connect_args')}")
    else:
        logger.info(f"create_async_engine_safe: creating async engine for {url}")

    try:
        engine = create_async_engine(url, **kwargs)
        return engine
    except Exception as e:
        logger.error(f"create_async_engine_safe: failed to create engine for {url}: {e}")
        raise

temp_async_engine = create_async_engine_safe("sqlite+aiosqlite:///./data/flowslide.db", echo=False)

SessionLocal = sessionmaker(autocommit=False, autoflush=False, bind=temp_engine)
AsyncSessionLocal = async_sessionmaker(temp_async_engine, class_=AsyncSession, expire_on_commit=False)


def get_db():
    """Dependency to get database session"""
    db = SessionLocal()
    try:
        yield db
    finally:
        db.close()


async def get_async_db():
    """Dependency to get async database session"""
    if AsyncSessionLocal:
        async with AsyncSessionLocal() as session:
            yield session
    else:
        raise RuntimeError("Async database session not available")


async def init_db():
    """Initialize database tables with error handling"""
    try:
        # Import here to avoid circular imports
        from .models import Base

        logger.info(f"ğŸ—„ï¸ Initializing database tables using {DATABASE_TYPE}...")

        if async_engine and engine:
            # Use sync engine for table creation to avoid pgbouncer issues
            with engine.begin() as conn:
                # Create all tables
                Base.metadata.create_all(bind=engine)

            logger.info("âœ… Database tables created successfully")

            # Initialize default admin user - always create one regardless of mode
            from ..auth.auth_service import init_default_admin

            try:
                # Always initialize default admin user for all deployment modes
                # This ensures there's always at least one admin user available
                db = SessionLocal()
                init_default_admin(db)
                logger.info("âœ… Default admin user initialized for all deployment modes")
            except Exception as e:
                logger.warning(f"âš ï¸ Admin user initialization warning: {e}")
            finally:
                if 'db' in locals():
                    db.close()
        else:
            raise RuntimeError("Database engine not initialized")

    except Exception as e:
        logger.error(f"âŒ Database initialization failed: {e}")
        # Try to handle the error gracefully
        if "postgresql" in str(e).lower() or "asyncpg" in str(e).lower():
            logger.error("ğŸ’¡ Hint: This appears to be a PostgreSQL connection issue.")
            logger.error("   Consider checking your DATABASE_URL or using SQLite as fallback.")
        raise


async def close_db():
    """Close database connections"""
    if async_engine:
        try:
            await asyncio.wait_for(async_engine.dispose(), timeout=5)
        except asyncio.TimeoutError:
            logger.warning("Warning: async_engine.dispose() timed out after 5s")
        except asyncio.CancelledError:
            logger.warning("Warning: async_engine.dispose() was cancelled")
        except Exception as e:
            logger.warning(f"Warning: exception during async_engine.dispose(): {e}")


def update_session_makers():
    """æ›´æ–°session makersä»¥ä½¿ç”¨æ­£ç¡®çš„å¼•æ“"""
    global SessionLocal, AsyncSessionLocal

    if engine:
        SessionLocal = sessionmaker(autocommit=False, autoflush=False, bind=engine)

    if async_engine:
        AsyncSessionLocal = async_sessionmaker(async_engine, class_=AsyncSession, expire_on_commit=False)


def get_auth_db():
    """Dependency to get database session for authentication (based on deployment mode)"""
    from ..core.deployment_mode_manager import mode_manager

    # Ensure database manager is initialized
    if not db_manager.primary_engine:
        db_manager.initialize()

    try:
        current_mode = mode_manager.current_mode or mode_manager.detect_current_mode()
        mode_name = current_mode.value if current_mode else 'local_only'
    except Exception:
        mode_name = 'local_only'

    # For local and local_r2 modes, use local database
    if mode_name in ['local_only', 'local_r2']:
        # Use local database
        db = SessionLocal()
        try:
            yield db
        finally:
            db.close()
    # For local_external and local_external_r2 modes, use external database
    elif mode_name in ['local_external', 'local_external_r2']:
        if db_manager.external_engine:
            # Create session with external engine
            from sqlalchemy.orm import sessionmaker
            ExternalSessionLocal = sessionmaker(autocommit=False, autoflush=False, bind=db_manager.external_engine)
            db = ExternalSessionLocal()
            try:
                yield db
            finally:
                db.close()
        else:
            # Fallback to local if external not available
            logger.warning("âš ï¸ External database not available, falling back to local for authentication")
            db = SessionLocal()
            try:
                yield db
            finally:
                db.close()
    else:
        # Default to local
        db = SessionLocal()
        try:
            yield db
        finally:
            db.close()


async def get_auth_async_db():
    """Dependency to get async database session for authentication (based on deployment mode)"""
    from ..core.deployment_mode_manager import mode_manager

    try:
        current_mode = mode_manager.current_mode or mode_manager.detect_current_mode()
        mode_name = current_mode.value if current_mode else 'local_only'
    except Exception:
        mode_name = 'local_only'

    # For local and local_r2 modes, use local database
    if mode_name in ['local_only', 'local_r2']:
        # Use local database
        if AsyncSessionLocal:
            async with AsyncSessionLocal() as session:
                yield session
        else:
            raise RuntimeError("Async database session not available")
    # For local_external and local_external_r2 modes, use external database
    elif mode_name in ['local_external', 'local_external_r2']:
        if db_manager.external_async_engine:
            # Create session with external async engine
            from sqlalchemy.ext.asyncio import async_sessionmaker, AsyncSession
            ExternalAsyncSessionLocal = async_sessionmaker(db_manager.external_async_engine, class_=AsyncSession, expire_on_commit=False)
            async with ExternalAsyncSessionLocal() as session:
                yield session
        else:
            # Fallback to local if external not available
            logger.warning("âš ï¸ External async database not available, falling back to local for authentication")
            if AsyncSessionLocal:
                async with AsyncSessionLocal() as session:
                    yield session
            else:
                raise RuntimeError("Async database session not available")


def update_session_makers():
    """Update session makers after database initialization"""
    global SessionLocal, AsyncSessionLocal

    if db_manager.primary_engine and db_manager.primary_async_engine:
        SessionLocal = sessionmaker(autocommit=False, autoflush=False, bind=db_manager.primary_engine)
        AsyncSessionLocal = async_sessionmaker(db_manager.primary_async_engine, class_=AsyncSession, expire_on_commit=False)
        logger.info("âœ… Database session makers updated")
    else:
        logger.warning("âš ï¸ Database engines not available, session makers not updated")
