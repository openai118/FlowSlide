"""
å¤‡ä»½ç®¡ç†APIæ¥å£
æä¾›REST APIæ¥ç®¡ç†æ•°æ®å¤‡ä»½ã€æ¢å¤å’Œç›‘æ§åŠŸèƒ½
"""

import os
import psutil
import logging
from datetime import datetime
from pathlib import Path
from typing import List, Dict, Any, Optional
from fastapi import APIRouter, HTTPException, BackgroundTasks
from fastapi.responses import FileResponse
from pydantic import BaseModel

from ..services.backup_service import backup_service, create_backup, list_backups
from ..database import db_manager

router = APIRouter(prefix="/api/backup", tags=["Backup Management"])
logger = logging.getLogger(__name__)


class BackupConfig(BaseModel):
    """å¤‡ä»½é…ç½®"""
    auto_backup_enabled: bool = True
    backup_interval: int = 24  # å°æ—¶
    max_backups: int = 10
    retention_days: int = 30


@router.post("/database")
async def create_database_backup():
    """åˆ›å»ºæ•°æ®åº“å¤‡ä»½"""
    try:
        logger.info("ğŸ“¦ Starting database backup...")

        # åˆ›å»ºæ•°æ®åº“å¤‡ä»½
        backup_path = await create_backup("db_only")

        # è·å–å¤‡ä»½ä¿¡æ¯
        backup_file = Path(backup_path)
        backup_info = {
            "filename": backup_file.name,
            "size": backup_file.stat().st_size,
            "created_at": datetime.fromtimestamp(backup_file.stat().st_mtime).isoformat(),
            "path": str(backup_file)
        }

        logger.info(f"âœ… Database backup completed: {backup_file.name}")
        return {
            "success": True,
            "message": "æ•°æ®åº“å¤‡ä»½åˆ›å»ºæˆåŠŸ",
            "backup_info": backup_info
        }

    except Exception as e:
        logger.error(f"âŒ Database backup failed: {e}")
        raise HTTPException(status_code=500, detail=f"åˆ›å»ºæ•°æ®åº“å¤‡ä»½å¤±è´¥: {str(e)}")


@router.get("/download/latest")
async def download_latest_backup():
    """ä¸‹è½½æœ€æ–°çš„å¤‡ä»½æ–‡ä»¶"""
    try:
        backups = await list_backups()
        if not backups:
            raise HTTPException(status_code=404, detail="æ²¡æœ‰æ‰¾åˆ°å¤‡ä»½æ–‡ä»¶")

        latest_backup = backups[0]  # å·²ç»æŒ‰æ—¶é—´æ’åº
        backup_path = Path(latest_backup["path"])

        if not backup_path.exists():
            raise HTTPException(status_code=404, detail="å¤‡ä»½æ–‡ä»¶ä¸å­˜åœ¨")

        return FileResponse(
            path=backup_path,
            filename=backup_path.name,
            media_type="application/zip"
        )

    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"âŒ Download backup failed: {e}")
        raise HTTPException(status_code=500, detail=f"ä¸‹è½½å¤‡ä»½å¤±è´¥: {str(e)}")


@router.post("/sync/r2")
async def sync_to_r2():
    """åŒæ­¥å¤‡ä»½åˆ°R2äº‘å­˜å‚¨"""
    try:
        logger.info("â˜ï¸ Starting R2 sync...")

        # åŒæ­¥åˆ°R2
        sync_info = await backup_service.sync_to_r2()

        # æ›´æ–°æœ€ååŒæ­¥æ—¶é—´åˆ°ç¯å¢ƒå˜é‡
        import os
        from datetime import datetime
        os.environ["LAST_R2_SYNC_TIME"] = datetime.now().isoformat()

        # å¦‚æœæœ‰.envæ–‡ä»¶ï¼Œä¹Ÿæ›´æ–°åˆ°æ–‡ä»¶
        try:
            env_file = Path(".env")
            if env_file.exists():
                content = env_file.read_text()
                if "LAST_R2_SYNC_TIME" in content:
                    # æ›´æ–°ç°æœ‰è¡Œ
                    lines = content.split('\n')
                    for i, line in enumerate(lines):
                        if line.startswith("LAST_R2_SYNC_TIME="):
                            lines[i] = f"LAST_R2_SYNC_TIME={datetime.now().isoformat()}"
                            break
                    content = '\n'.join(lines)
                else:
                    # æ·»åŠ æ–°è¡Œ
                    content += f"\nLAST_R2_SYNC_TIME={datetime.now().isoformat()}"
                env_file.write_text(content)
        except Exception as e:
            logger.warning(f"æ›´æ–°.envæ–‡ä»¶å¤±è´¥: {e}")

        logger.info(f"âœ… R2 sync completed: {sync_info['filename']}")
        return {
            "success": True,
            "message": "å¤‡ä»½åŒæ­¥åˆ°R2æˆåŠŸ",
            "sync_info": sync_info
        }

    except Exception as e:
        logger.error(f"âŒ R2 sync failed: {e}")
        raise HTTPException(status_code=500, detail=f"åŒæ­¥åˆ°R2å¤±è´¥: {str(e)}")


@router.post("/restore/r2")
async def restore_from_r2():
    """ä»R2äº‘å­˜å‚¨æ¢å¤æ•°æ®"""
    try:
        logger.info("ğŸ”„ Starting R2 restore...")

        # æ£€æŸ¥R2é…ç½®
        if not backup_service._is_r2_configured():
            raise HTTPException(status_code=400, detail="R2äº‘å­˜å‚¨æœªé…ç½®")

        # å®ç°R2æ¢å¤é€»è¾‘
        restore_result = await backup_service.restore_from_r2()

        logger.info(f"âœ… R2 restore completed: {restore_result}")
        return {
            "message": "ä»R2æ¢å¤æˆåŠŸ",
            "restore_info": restore_result
        }

    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"âŒ R2 restore failed: {e}")
        raise HTTPException(status_code=500, detail=f"ä»R2æ¢å¤å¤±è´¥: {str(e)}")


@router.get("/history")
async def get_backup_history():
    """è·å–å¤‡ä»½å†å²"""
    try:
        backups = await list_backups()

        # æ ¼å¼åŒ–å¤‡ä»½ä¿¡æ¯
        formatted_backups = []
        for backup in backups:
            backup_file = Path(backup["path"])
            formatted_backups.append({
                "filename": backup["name"],
                "size": backup["size"],
                "created_at": backup["created"],
                "path": backup["path"]
            })

        return {
            "success": True,
            "backups": formatted_backups
        }

    except Exception as e:
        logger.error(f"âŒ Get backup history failed: {e}")
        raise HTTPException(status_code=500, detail=f"è·å–å¤‡ä»½å†å²å¤±è´¥: {str(e)}")


@router.post("/cleanup")
async def cleanup_old_backups():
    """æ¸…ç†æ—§å¤‡ä»½æ–‡ä»¶"""
    try:
        logger.info("ğŸ—‘ï¸ Starting backup cleanup...")

        initial_count = len(await list_backups())

        # æ¸…ç†æ—§å¤‡ä»½
        await backup_service._cleanup_old_backups()

        final_count = len(await list_backups())
        deleted_count = initial_count - final_count

        logger.info(f"âœ… Cleanup completed. Deleted {deleted_count} old backups")
        return {
            "success": True,
            "message": f"æ¸…ç†å®Œæˆï¼Œåˆ é™¤äº† {deleted_count} ä¸ªæ—§å¤‡ä»½æ–‡ä»¶",
            "deleted_count": deleted_count
        }

    except Exception as e:
        logger.error(f"âŒ Cleanup failed: {e}")
        raise HTTPException(status_code=500, detail=f"æ¸…ç†æ—§å¤‡ä»½å¤±è´¥: {str(e)}")


@router.get("/config")
async def get_backup_config():
    """è·å–å¤‡ä»½é…ç½®"""
    try:
        config = {
            "auto_backup_enabled": os.getenv("AUTO_BACKUP_ENABLED", "true").lower() == "true",
            "backup_interval": int(os.getenv("BACKUP_INTERVAL", "24")),
            "max_backups": int(os.getenv("MAX_BACKUPS", "10")),
            "retention_days": backup_service.retention_days
        }

        return {
            "success": True,
            "config": config
        }

    except Exception as e:
        logger.error(f"âŒ Get backup config failed: {e}")
        raise HTTPException(status_code=500, detail=f"è·å–å¤‡ä»½é…ç½®å¤±è´¥: {str(e)}")


@router.post("/config")
async def save_backup_config(config: BackupConfig):
    """ä¿å­˜å¤‡ä»½é…ç½®"""
    try:
        logger.info("âš™ï¸ Saving backup configuration...")

        # ä¿å­˜é…ç½®åˆ°ç¯å¢ƒå˜é‡
        import os
        from pathlib import Path

        # è·å–.envæ–‡ä»¶è·¯å¾„
        env_file = Path(".env")

        # è¯»å–ç°æœ‰ç¯å¢ƒå˜é‡
        env_vars = {}
        if env_file.exists():
            with open(env_file, 'r', encoding='utf-8') as f:
                for line in f:
                    line = line.strip()
                    if line and not line.startswith('#'):
                        if '=' in line:
                            key, value = line.split('=', 1)
                            env_vars[key.strip()] = value.strip()

        # æ›´æ–°å¤‡ä»½ç›¸å…³é…ç½®
        env_vars['AUTO_BACKUP_ENABLED'] = str(config.auto_backup_enabled).lower()
        env_vars['BACKUP_INTERVAL'] = str(config.backup_interval)
        env_vars['MAX_BACKUPS'] = str(config.max_backups)
        env_vars['BACKUP_RETENTION_DAYS'] = str(config.retention_days)

        # å†™å›.envæ–‡ä»¶
        with open(env_file, 'w', encoding='utf-8') as f:
            for key, value in env_vars.items():
                f.write(f"{key}={value}\n")

        # æ›´æ–°è¿è¡Œæ—¶ç¯å¢ƒå˜é‡
        os.environ['AUTO_BACKUP_ENABLED'] = str(config.auto_backup_enabled).lower()
        os.environ['BACKUP_INTERVAL'] = str(config.backup_interval)
        os.environ['MAX_BACKUPS'] = str(config.max_backups)
        os.environ['BACKUP_RETENTION_DAYS'] = str(config.retention_days)

        # æ›´æ–°backup_serviceçš„é…ç½®
        backup_service.retention_days = config.retention_days

        logger.info("âœ… Backup configuration saved")
        return {
            "success": True,
            "message": "å¤‡ä»½é…ç½®ä¿å­˜æˆåŠŸ",
            "config": config.dict()
        }

    except Exception as e:
        logger.error(f"âŒ Save backup config failed: {e}")
        raise HTTPException(status_code=500, detail=f"ä¿å­˜å¤‡ä»½é…ç½®å¤±è´¥: {str(e)}")
