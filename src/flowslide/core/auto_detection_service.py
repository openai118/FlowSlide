"""
è‡ªåŠ¨æ£€æµ‹æœåŠ¡ - æ ¹æ®å¤–éƒ¨æ•°æ®åº“å’ŒR2çš„æœ‰æ•ˆé…ç½®è‡ªåŠ¨ç¡®å®šè¿è¡Œæ¨¡å¼
"""

import os
import logging
import asyncio
from typing import Dict, Any, Optional, Tuple
from dataclasses import dataclass
from enum import Enum

import boto3
from botocore.exceptions import ClientError, NoCredentialsError
from sqlalchemy import text, create_engine
from ..database.database import create_async_engine_safe

from ..core.sync_strategy_config import DeploymentMode

logger = logging.getLogger(__name__)


class ServiceStatus(Enum):
    """æœåŠ¡çŠ¶æ€"""
    AVAILABLE = "available"
    UNAVAILABLE = "unavailable"
    CONFIG_MISSING = "config_missing"
    CONNECTION_FAILED = "connection_failed"


@dataclass
class ServiceCheckResult:
    """æœåŠ¡æ£€æŸ¥ç»“æœ"""
    status: ServiceStatus
    message: str
    response_time_ms: Optional[float] = None
    error_details: Optional[str] = None


class AutoDetectionService:
    """è‡ªåŠ¨æ£€æµ‹æœåŠ¡"""

    def __init__(self):
        self.cache_timeout = 300  # 5åˆ†é’Ÿç¼“å­˜
        self._cache: Dict[str, Tuple[ServiceCheckResult, float]] = {}

    def _is_cache_valid(self, service_name: str) -> bool:
        """æ£€æŸ¥ç¼“å­˜æ˜¯å¦æœ‰æ•ˆ"""
        if service_name not in self._cache:
            return False

        result, timestamp = self._cache[service_name]
        import time
        return (time.time() - timestamp) < self.cache_timeout

    def _cache_result(self, service_name: str, result: ServiceCheckResult):
        """ç¼“å­˜æ£€æµ‹ç»“æœ"""
        import time
        self._cache[service_name] = (result, time.time())

    def _get_cached_result(self, service_name: str) -> Optional[ServiceCheckResult]:
        """è·å–ç¼“å­˜çš„æ£€æµ‹ç»“æœ"""
        if self._is_cache_valid(service_name):
            return self._cache[service_name][0]
        return None

    async def check_external_database(self) -> ServiceCheckResult:
        """æ£€æŸ¥å¤–éƒ¨æ•°æ®åº“è¿æ¥"""
        # æ£€æŸ¥ç¼“å­˜
        cached = self._get_cached_result("external_db")
        if cached:
            return cached

        try:
            # åŠ¨æ€å¯¼å…¥é…ç½®ä»¥é¿å…å¾ªç¯å¯¼å…¥
            from .simple_config import DATABASE_URL, LOCAL_DATABASE_URL, DATABASE_MODE, EXTERNAL_DATABASE_URL

            # If an explicit EXTERNAL_DATABASE_URL is configured in env, prefer it for detection
            database_url = (EXTERNAL_DATABASE_URL or DATABASE_URL or "").strip()
            database_mode = DATABASE_MODE
            
            # å¦‚æœä½¿ç”¨çš„æ˜¯æœ¬åœ°æ•°æ®åº“URLï¼Œåˆ™è®¤ä¸ºæ˜¯æœ¬åœ°æ¨¡å¼
            if (not database_url) or database_url == LOCAL_DATABASE_URL or database_url.startswith("sqlite:///"):
                result = ServiceCheckResult(
                    status=ServiceStatus.UNAVAILABLE,
                    message="ä½¿ç”¨çš„æ˜¯æœ¬åœ°SQLiteæ•°æ®åº“"
                )
                self._cache_result("external_db", result)
                return result

            # If caller explicitly disables external DB detection via env, skip attempting connection
            disable_detection = os.getenv("DISABLE_EXTERNAL_DB_DETECTION", "").strip().lower() in ("1","true","yes")
            if disable_detection:
                result = ServiceCheckResult(
                    status=ServiceStatus.UNAVAILABLE,
                    message="å¤–éƒ¨æ•°æ®åº“æ£€æµ‹å·²è¢«ç¯å¢ƒå˜é‡ç¦ç”¨"
                )
                self._cache_result("external_db", result)
                return result

            # Note: previously DATABASE_MODE=='local' short-circuited here and returned UNAVAILABLE.
            # Change: if an EXTERNAL_DATABASE_URL is configured, we should attempt to connect and
            # report actual availability. This does not change which DB is used as primary; it
            # only provides an accurate detection of external DB accessibility.

            # æ£€æŸ¥æ˜¯å¦æ˜¯æœ‰æ•ˆçš„å¤–éƒ¨æ•°æ®åº“URL
            if not (database_url.startswith("postgresql://") or database_url.startswith("mysql://")):
                result = ServiceCheckResult(
                    status=ServiceStatus.UNAVAILABLE,
                    message="ä¸æ˜¯æœ‰æ•ˆçš„å¤–éƒ¨æ•°æ®åº“URLæ ¼å¼"
                )
                self._cache_result("external_db", result)
                return result

            # å°è¯•è¿æ¥æ•°æ®åº“ï¼ˆåªæœ‰è¿æ¥æˆåŠŸæ‰ç®— AVAILABLEï¼‰
            import time
            start_time = time.time()

            # åˆ›å»ºå¼‚æ­¥å¼•æ“è¿›è¡Œæµ‹è¯•
            # If asyncpg is used behind pgbouncer, disable asyncpg's statement cache
            # by setting statement_cache_size=0 (or read from PG_STATEMENT_CACHE_SIZE env).
            # å¼ºåˆ¶æ‰€æœ‰ asyncpg åœºæ™¯ç¦ç”¨ prepared statement ç¼“å­˜ï¼Œé¿å… pgbouncer é—®é¢˜
            async_connect_args = {"statement_cache_size": 0}
            try:
                # Convert sync DATABASE_URL to async form if needed
                from .simple_config import get_async_database_url
                async_db_url = get_async_database_url(database_url)
            except Exception:
                async_db_url = database_url

            async_engine = create_async_engine_safe(async_db_url, echo=False, connect_args=async_connect_args)

            try:
                async with async_engine.connect() as conn:
                    # æ‰§è¡Œç®€å•æŸ¥è¯¢æµ‹è¯•è¿æ¥
                    result = await conn.execute(text("SELECT 1 as test"))
                    row = result.fetchone()

                    response_time = (time.time() - start_time) * 1000

                    if row and row[0] == 1:
                        check_result = ServiceCheckResult(
                            status=ServiceStatus.AVAILABLE,
                            message="å¤–éƒ¨æ•°æ®åº“è¿æ¥æ­£å¸¸",
                            response_time_ms=round(response_time, 2)
                        )
                    else:
                        check_result = ServiceCheckResult(
                            status=ServiceStatus.CONNECTION_FAILED,
                            message="æ•°æ®åº“è¿æ¥æµ‹è¯•å¤±è´¥ï¼šæŸ¥è¯¢è¿”å›å¼‚å¸¸ç»“æœ",
                            response_time_ms=round(response_time, 2)
                        )

            except Exception as e:
                # Async attempt failed. As a compatibility measure for environments
                # using pgbouncer (Supabase), try a short synchronous psycopg2
                # connection as a fallback. Many poolers are incompatible with
                # asyncpg prepared statement caching; a plain sync connection
                # avoids that issue and gives a reliable availability signal.
                response_time = (time.time() - start_time) * 1000

                sync_fallback_disabled = os.getenv("DISABLE_SYNC_DB_FALLBACK", "").strip().lower() in ("1","true","yes")

                if sync_fallback_disabled:
                    check_result = ServiceCheckResult(
                        status=ServiceStatus.CONNECTION_FAILED,
                        message=f"å¤–éƒ¨æ•°æ®åº“å¼‚æ­¥æ£€æµ‹å¤±è´¥ï¼ˆæœªå°è¯•åŒæ­¥å›é€€ï¼‰: {str(e)}",
                        response_time_ms=round(response_time, 2),
                        error_details=str(e)
                    )
                else:
                    # Try psycopg2 sync connect as a quick health check
                    try:
                        import psycopg2
                    except Exception as ie:
                        check_result = ServiceCheckResult(
                            status=ServiceStatus.CONNECTION_FAILED,
                            message=("å¤–éƒ¨æ•°æ®åº“å¼‚æ­¥æ£€æµ‹å¤±è´¥ï¼Œä¸”æœªæ‰¾åˆ° psycopg2 åº“ä»¥æ‰§è¡ŒåŒæ­¥å›é€€: "
                                     f"async_error={str(e)} sync_import_error={str(ie)}"),
                            response_time_ms=round(response_time, 2),
                            error_details=f"async:{str(e)}; sync_import:{str(ie)}"
                        )
                    else:
                        try:
                            # Use a short timeout to avoid long blocking
                            sync_start = time.time()
                            # psycopg2 accepts a libpq connection string / URI
                            conn = psycopg2.connect(database_url, connect_timeout=5)
                            cur = conn.cursor()
                            cur.execute("SELECT 1")
                            row = cur.fetchone()
                            cur.close()
                            conn.close()
                            sync_response_time = (time.time() - sync_start) * 1000

                            if row and row[0] == 1:
                                check_result = ServiceCheckResult(
                                    status=ServiceStatus.AVAILABLE,
                                    message=("å¤–éƒ¨æ•°æ®åº“è¿æ¥æ­£å¸¸ï¼ˆé€šè¿‡åŒæ­¥ psycopg2 å›é€€æ£€æµ‹ï¼‰"),
                                    response_time_ms=round(sync_response_time, 2)
                                )
                            else:
                                check_result = ServiceCheckResult(
                                    status=ServiceStatus.CONNECTION_FAILED,
                                    message=("å¤–éƒ¨æ•°æ®åº“åŒæ­¥å›é€€æ£€æµ‹å¤±è´¥ï¼šæŸ¥è¯¢è¿”å›å¼‚å¸¸ç»“æœ"),
                                    response_time_ms=round(sync_response_time, 2),
                                    error_details=f"async_error:{str(e)}"
                                )
                        except Exception as se:
                            sync_response_time = (time.time() - start_time) * 1000
                            check_result = ServiceCheckResult(
                                status=ServiceStatus.CONNECTION_FAILED,
                                message=("å¤–éƒ¨æ•°æ®åº“åŒæ­¥å›é€€æ£€æµ‹å¤±è´¥: " + str(se)),
                                response_time_ms=round(sync_response_time, 2),
                                error_details=f"async_error:{str(e)}; sync_error:{str(se)}"
                            )

            finally:
                await async_engine.dispose()

            self._cache_result("external_db", check_result)
            return check_result

        except Exception as e:
            result = ServiceCheckResult(
                status=ServiceStatus.CONNECTION_FAILED,
                message=f"å¤–éƒ¨æ•°æ®åº“æ£€æµ‹è¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {str(e)}",
                error_details=str(e)
            )
            self._cache_result("external_db", result)
            return result

    async def check_r2_storage(self) -> ServiceCheckResult:
        """æ£€æŸ¥R2äº‘å­˜å‚¨è¿æ¥"""
        # æ£€æŸ¥ç¼“å­˜
        cached = self._get_cached_result("r2")
        if cached:
            return cached

        try:
            import time
            start_time = time.time()

            # æ£€æŸ¥R2é…ç½®
            r2_config = {
                "access_key": os.getenv("R2_ACCESS_KEY_ID"),
                "secret_key": os.getenv("R2_SECRET_ACCESS_KEY"),
                "endpoint": os.getenv("R2_ENDPOINT"),
                "bucket": os.getenv("R2_BUCKET_NAME")
            }

            # ä¸¥æ ¼å®Œæ•´æ€§ï¼šå…¨éƒ¨å››é¡¹éƒ½éç©ºæ‰ç»§ç»­
            if not all(r2_config.values()):
                missing_configs = [k for k,v in r2_config.items() if not v]
                result = ServiceCheckResult(
                    status=ServiceStatus.CONFIG_MISSING,
                    message=f"R2é…ç½®ä¸å®Œæ•´ï¼Œç¼ºå°‘: {', '.join(missing_configs)}"
                )
                self._cache_result("r2", result)
                return result

            # åˆ›å»ºS3å®¢æˆ·ç«¯è¿æ¥R2
            s3_client = boto3.client(
                's3',
                aws_access_key_id=r2_config["access_key"],
                aws_secret_access_key=r2_config["secret_key"],
                endpoint_url=r2_config["endpoint"],
                region_name='auto'  # Cloudflare R2ä½¿ç”¨auto region
            )

            # æµ‹è¯•è¿æ¥ï¼šå°è¯•åˆ—å‡ºbucketä¸­çš„å¯¹è±¡ï¼ˆæœ€å¤š1ä¸ªï¼‰
            try:
                response = s3_client.list_objects_v2(
                    Bucket=r2_config["bucket"],
                    MaxKeys=1
                )

                response_time = (time.time() - start_time) * 1000

                check_result = ServiceCheckResult(
                    status=ServiceStatus.AVAILABLE,
                    message="R2äº‘å­˜å‚¨è¿æ¥æ­£å¸¸",
                    response_time_ms=round(response_time, 2)
                )

            except NoCredentialsError as e:
                response_time = (time.time() - start_time) * 1000
                check_result = ServiceCheckResult(
                    status=ServiceStatus.CONNECTION_FAILED,
                    message="R2å‡­æ®æ— æ•ˆï¼Œè¯·æ£€æŸ¥Access Keyå’ŒSecret Key",
                    response_time_ms=round(response_time, 2),
                    error_details=str(e)
                )

            except ClientError as e:
                response_time = (time.time() - start_time) * 1000
                error_code = e.response.get('Error', {}).get('Code', 'Unknown')

                if error_code == 'NoSuchBucket':
                    check_result = ServiceCheckResult(
                        status=ServiceStatus.CONNECTION_FAILED,
                        message=f"R2å­˜å‚¨æ¡¶ '{r2_config['bucket']}' ä¸å­˜åœ¨",
                        response_time_ms=round(response_time, 2),
                        error_details=error_code
                    )
                elif error_code == 'AccessDenied':
                    check_result = ServiceCheckResult(
                        status=ServiceStatus.CONNECTION_FAILED,
                        message="R2è®¿é—®è¢«æ‹’ç»ï¼Œè¯·æ£€æŸ¥æƒé™è®¾ç½®",
                        response_time_ms=round(response_time, 2),
                        error_details=error_code
                    )
                else:
                    check_result = ServiceCheckResult(
                        status=ServiceStatus.CONNECTION_FAILED,
                        message=f"R2è¿æ¥å¤±è´¥: {error_code}",
                        response_time_ms=round(response_time, 2),
                        error_details=error_code
                    )

            except Exception as e:
                response_time = (time.time() - start_time) * 1000
                check_result = ServiceCheckResult(
                    status=ServiceStatus.CONNECTION_FAILED,
                    message=f"R2è¿æ¥æµ‹è¯•å¼‚å¸¸: {str(e)}",
                    response_time_ms=round(response_time, 2),
                    error_details=str(e)
                )

            self._cache_result("r2", check_result)
            return check_result

        except Exception as e:
            result = ServiceCheckResult(
                status=ServiceStatus.CONNECTION_FAILED,
                message=f"R2æ£€æµ‹è¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {str(e)}",
                error_details=str(e)
            )
            self._cache_result("r2", result)
            return result

    async def detect_deployment_mode(self) -> DeploymentMode:
        """è‡ªåŠ¨æ£€æµ‹éƒ¨ç½²æ¨¡å¼"""
        logger.info("ğŸ” å¼€å§‹è‡ªåŠ¨æ£€æµ‹éƒ¨ç½²æ¨¡å¼...")

        # å¹¶è¡Œæ£€æŸ¥å¤–éƒ¨æ•°æ®åº“å’ŒR2
        db_task = asyncio.create_task(self.check_external_database())
        r2_task = asyncio.create_task(self.check_r2_storage())

        db_result, r2_result = await asyncio.gather(db_task, r2_task)

        # è®°å½•æ£€æµ‹ç»“æœ
        logger.info(f"ğŸ“Š å¤–éƒ¨æ•°æ®åº“æ£€æµ‹ç»“æœ: {db_result.status.value} - {db_result.message}")
        logger.info(f"ğŸ“Š R2å­˜å‚¨æ£€æµ‹ç»“æœ: {r2_result.status.value} - {r2_result.message}")

        # æ ¹æ®æ£€æµ‹ç»“æœç¡®å®šéƒ¨ç½²æ¨¡å¼
        has_external_db = db_result.status == ServiceStatus.AVAILABLE
        has_r2 = r2_result.status == ServiceStatus.AVAILABLE

        if has_external_db and has_r2:
            detected_mode = DeploymentMode.LOCAL_EXTERNAL_R2
            logger.info("ğŸ¯ æ£€æµ‹åˆ°éƒ¨ç½²æ¨¡å¼: æœ¬åœ°+å¤–éƒ¨æ•°æ®åº“+R2")
        elif has_external_db:
            detected_mode = DeploymentMode.LOCAL_EXTERNAL
            logger.info("ğŸ¯ æ£€æµ‹åˆ°éƒ¨ç½²æ¨¡å¼: æœ¬åœ°+å¤–éƒ¨æ•°æ®åº“")
        elif has_r2:
            detected_mode = DeploymentMode.LOCAL_R2
            logger.info("ğŸ¯ æ£€æµ‹åˆ°éƒ¨ç½²æ¨¡å¼: æœ¬åœ°+R2")
        else:
            detected_mode = DeploymentMode.LOCAL_ONLY
            logger.info("ğŸ¯ æ£€æµ‹åˆ°éƒ¨ç½²æ¨¡å¼: ä»…æœ¬åœ°")

        return detected_mode

    def clear_cache(self):
        """æ¸…é™¤æ£€æµ‹ç¼“å­˜"""
        self._cache.clear()
        logger.info("ğŸ§¹ å·²æ¸…é™¤è‡ªåŠ¨æ£€æµ‹ç¼“å­˜")

    async def get_service_status(self) -> Dict[str, Any]:
        """è·å–æ‰€æœ‰æœåŠ¡çš„çŠ¶æ€"""
        db_result = await self.check_external_database()
        r2_result = await self.check_r2_storage()

        return {
            "external_database": {
                "status": db_result.status.value,
                "message": db_result.message,
                "response_time_ms": db_result.response_time_ms,
                "error_details": db_result.error_details
            },
            "r2_storage": {
                "status": r2_result.status.value,
                "message": r2_result.message,
                "response_time_ms": r2_result.response_time_ms,
                "error_details": r2_result.error_details
            }
        }


# åˆ›å»ºå…¨å±€è‡ªåŠ¨æ£€æµ‹æœåŠ¡å®ä¾‹
auto_detection_service = AutoDetectionService()